{"meta":{"title":"Vic's Blog","subtitle":"code changes the world","description":"","author":"vic","url":"http://geekvic.top","root":"/"},"pages":[{"title":"标签","date":"2020-04-03T09:06:19.000Z","updated":"2020-05-19T07:07:30.517Z","comments":true,"path":"tags/index.html","permalink":"http://geekvic.top/tags/index.html","excerpt":"","text":""},{"title":"关于我","date":"2020-04-03T09:19:04.000Z","updated":"2020-05-19T07:07:30.211Z","comments":true,"path":"about/index.html","permalink":"http://geekvic.top/about/index.html","excerpt":"","text":"本人有8年左右的技术开发经验、技术栈全面，前后端、架构设计都有涉足，主要以Java开发为主，除了丰富的开发经验外，还有多年的团队管理经验。当前主要负责技术选型、软件架构设计、核心功能开发、基础组件研发，并参与日常团队管理与建设。 熟练掌握Java、HTML、js、jQuery、Flex等； 精通J2EE，熟悉Spring、Spring MVC、MyBatis、Spring Boot等Java主流开源框架； 熟练使用Dubbo、Zookeeper用于搭建微服务，包括Dubbo Admin服务治理，了解Spring Cloud； 熟练使用RocketMQ、ActiveMQ等消息队列； 熟悉Java多线程、JVM原理以及性能调优、定时任务、Apollo配置、分布式开发； 熟悉Linux系统，包括Linux常用命令，以及分布式文件系统NFS、FastDFS的使用； 熟悉Web通信协议，如SIP、Protobuf、Socket等协议； 熟悉系统监控工具，如Prometheus、AlertManager、Grafana； 熟悉Devops模式，包括Docker容器技术，日志分析系统ELK、Jenkins自动打包； 熟练使用MySQL，熟悉SQL Server、Oracle，熟悉Redis缓存、MongoDB、搜索引擎ES，熟悉数据库的分片规则，能对数据库进行水平拆分，熟练使用SQL，并能够对SQL性能进行优化 江苏省计算机偏软三级，熟练使用IDEA、Eclipse、VSCode等集成开发工具，熟练使用Maven、Nexus等工具，熟练使用Git、GitLab、SVN等版本管理工具； 获得系统集成项目管理工程师（中级）考试认证,并获得工程师职称认证；参与过CMMI3资格认证的培训； 工作认真，责任心强，具有较强的团队协作精神；学习能力强，愿意接受新事物、新技术；有轻微代码洁癖，对自己的代码有较高要求；"},{"title":"分类","date":"2020-04-03T09:06:46.000Z","updated":"2020-05-19T07:07:30.274Z","comments":true,"path":"categories/index.html","permalink":"http://geekvic.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"如何让Redis支持高可用","slug":"如何让Redis支持高可用","date":"2020-09-01T02:18:00.000Z","updated":"2020-09-01T09:39:52.747Z","comments":true,"path":"post/d254c291.html","link":"","permalink":"http://geekvic.top/post/d254c291.html","excerpt":"Redis实现高可用，支持三种集群模式：主从模式、哨兵模式以及cluster模式。 主从模式定义 在Redis集群中，让若干个Redis服务器去复制另一个Redis服务器，我们定义被复制的服务器为主服务器（master），而对主服务器进行复制的服务器则被称为从服务器（replica），这种模式叫做主从复制模式。 作用 为数据提供多个副本，支持高可用。 实现读写分离（主节点负责写，从节点负责读，主节点定期将数据同步到从节点，保证数据的一致性）。 任务分离，如从服务器负责备份工作和计算工作。 主从复制的特点","text":"Redis实现高可用，支持三种集群模式：主从模式、哨兵模式以及cluster模式。 主从模式定义 在Redis集群中，让若干个Redis服务器去复制另一个Redis服务器，我们定义被复制的服务器为主服务器（master），而对主服务器进行复制的服务器则被称为从服务器（replica），这种模式叫做主从复制模式。 作用 为数据提供多个副本，支持高可用。 实现读写分离（主节点负责写，从节点负责读，主节点定期将数据同步到从节点，保证数据的一致性）。 任务分离，如从服务器负责备份工作和计算工作。 主从复制的特点 主节点可以进行读写操作，当主节点数据变化后会自动将数据同步给从节点； 从节点一般都是只读的； 一个master可以拥有多个replica，但是一个replica只能有一个master； 其中一个replica挂了不影响其他replica的读和master的读和写，重新启动后会将数据从master同步过来； master挂了后不影响replica节点的读，但不再提供写服务，master重启后redis将重新对外提供写服务； master挂了后，不会在replica节点中重新选一个master； 工作机制 当replica启动后，主动向master发送SYNC命令。master接收到SYNC命令后在后台保存快照（RDB持久化）和缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给replica。replica接收到快照文件和命令后加载快照文件和缓存的执行命令。 复制初始化后，master每次接收到的写命令都会同步发送给slave，保证主从数据一致性。 主从复制搭建环境准备实现一主两从，同一台服务器上，master端口6379；两个replica，一个端口6380，另一个端口6381，如下图所示。 配置复制redis.conf文件，生成redis6380.conf以及redis6381.conf文件 master配置可以关闭rdb快照功能，将备份工作交给replica节点，aof功能可以开着，也可以关闭； replica配置 replicaof ：配置master服务的ip和端口，这样就建立起主从关系了。 masterauth ：如果master需要密码认证，这里需要配置master的密码，否则连接不上； replica-read-only：默认为yes，配置从服务默认为只读模式。 其中6380从服务的具体配置如下，6381的配置也是类似。 1234567891011121314151617port 6380pidfile /var/run/redis_6380.pidsave 900 1save 300 10save 60 10000dbfilename dump6380.rdbreplicaof localhost 6379replica-read-only yes appendonly yesappendfilename \"appendonly6380.aof\" 测试执行命令，通过redis客户端分别连接到主从redis服务 123./redis-cli -p 6379./redis-cli -p 6380./redis-cli -p 6381 主服务中查看replica信息 1info replication 显示信息 12345678910111213# Replicationrole:masterconnected_slaves:2slave0:ip=::1,port=6380,state=online,offset=123023,lag=0slave1:ip=::1,port=6381,state=online,offset=123023,lag=0master_replid:37d7bc32b5aca031ba762585137da938c78a77dcmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:123023second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:123023 从服务中查看信息 12345678910111213141516171819# Replicationrole:slavemaster_host:localhostmaster_port:6379master_link_status:upmaster_last_io_seconds_ago:8master_sync_in_progress:0slave_repl_offset:123205slave_priority:100slave_read_only:1connected_slaves:0master_replid:37d7bc32b5aca031ba762585137da938c78a77dcmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:123205second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:123205 redis主服务中添加名为name的key，在从服务中查看是否实现同步复制，如下面所示。 123456789127.0.0.1:6379&gt; set name vicOK127.0.0.1:6379&gt; 127.0.0.1:6380&gt; get name\"vic\"127.0.0.1:6381&gt; get name\"vic\" 至此，主从复制配置完成。 主从复制模式配置遇到的坑按照之前的配置，我发现redis的主从配置没有生效，从服务并没有连接到主服务，显示如下。 1master_link_status:down 本以为是防火墙问题，6379的端口没有打开，但通过netstat -lntp命令查看端口是开着的，又想着是不是主服务配置了密码，然后从服务没有配置密码引起的，结果发现并不是。 最后通过注释掉主服务的redis.conf文件里的bind 127.0.0.1就解决此问题了。 1#bind 127.0.0.1 哨兵模式概述哨兵模式是一种特殊的模式，哨兵是一个独立的进程，通过发送命令，等待Redis服务器响应，从而监控多个Redis实例，如下图所示。当主从服务中，主服务挂掉后，可以自动实现故障切换，而不需要手动去操作，因此更为推荐这种模式。 原理哨兵的作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 在Redis高可用架构中，Sentinel往往不是只有一个，而是有3个或者以上。目的是为了让其更加可靠，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式 故障切换当检测到主节点宕机后，断开与宕机主节点连接的所有从节点，在从节点中选取一个作为主节点，然后将其他的从节点连接到这个最新主节点的上。并且告知客户端最新的服务器地址。 相关概念主观下线SDOWN（subjectively down）,直接翻译的为主观下线,即当前sentinel实例认为某个redis服务为不可用状态. 客观下线ODOWN（objectively down）,直接翻译为客观下线,即多个sentinel实例都认为master处于SDOWN状态,那么此时master将处于ODOWN，ODOWN可以简单理解为master已经被集群确定为”不可用”，将会开启failover。 哨兵环境搭建在原来的主从复制测试环境的基础上，再配置sentinel.conf，并启动哨兵进程。 服务类型 主/从 端口 Redis 主 6379 Redis 从 6380 Redis 从 6381 Sentinel - 26379 Sentinel - 26380 Sentinel - 26381 配置sentinel.conf文件，复制三份，并进行修改，主要配置参数如下，三个文件区别主要是端口修改下，从26379~26381。 12345678910#当前Sentinel服务运行的端口port 26379 # 第一行配置指示 Sentinel去监视一个名为 mymaster的主服务器，这个主服务器的IP地址为127.0.0.1，端口号为6379，而将这个主服务器判断为失效至少需要2个Sentinel同意 sentinel monitor mymaster 127.0.0.1 6379 2# 10s内mymaster无响应，则认为mymaster宕机了sentinel down-after-milliseconds mymaster 10000#如果20秒后,mysater仍没启动过来，则启动failover sentinel failover-timeout mymaster 20000 # 执行故障转移时， 最多有1个从服务器同时对新的主服务器进行同步sentinel parallel-syncs mymaster 1 启动哨兵进程123/usr/local/bin/redis-sentinel sentinel.conf --sentinel &amp;/usr/local/bin/redis-sentinel sentinel6380.conf --sentinel &amp;/usr/local/bin/redis-sentinel sentinel6381.conf --sentinel &amp; 测试验证哨兵集群启动后，将6379主服务shutdown，这时候哨兵集群就会认定6379已经宕机，从而在6380和6381两台从服务里选举一个服务升级为master，然后再通知另一个服务，并自动修改它的配置文件，让它指向新的master，比如6380变成master，则6381则会自动变成6380的replica，当然如果我们现在再将6379启动起来，同样6379也会变成6380的replica，从而实现redis的故障自动转移。 遇到的坑1234567891011121314151623617:X 19 Aug 2020 16:01:43.844 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.23617:X 19 Aug 2020 16:01:43.844 # Sentinel ID is 6c4ad4b0df82b09a7d3078927182b59da3becb5f23617:X 19 Aug 2020 16:01:43.844 # +monitor master mymaster 127.0.0.1 6379 quorum 123617:X 19 Aug 2020 16:01:43.845 * +slave slave [::1]:6380 ::1 6380 @ mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:01:43.850 * +slave slave [::1]:6381 ::1 6381 @ mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:01:53.867 # +sdown slave [::1]:6381 ::1 6381 @ mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:01:53.867 # +sdown slave [::1]:6380 ::1 6380 @ mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.606 # +sdown master mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.606 # +odown master mymaster 127.0.0.1 6379 #quorum 1/123617:X 19 Aug 2020 16:03:55.606 # +new-epoch 123617:X 19 Aug 2020 16:03:55.606 # +try-failover master mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.610 # +vote-for-leader 6c4ad4b0df82b09a7d3078927182b59da3becb5f 123617:X 19 Aug 2020 16:03:55.610 # +elected-leader master mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.610 # +failover-state-select-slave master mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.669 # -failover-abort-no-good-slave master mymaster 127.0.0.1 637923617:X 19 Aug 2020 16:03:55.735 # Next failover delay: I will not start a failover before Wed Aug 19 16:09:55 2020 原因：脑裂脑裂，也就是说，某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的脑裂。 解决方法12min-slaves-to-write 1min-slaves-max-lag 10 表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。 cluster模式 哨兵解决和主从不能自动故障恢复的问题，但是同时也存在难以扩容以及单机存储、读写能力受限的问题，并且集群之前都是一台redis都是全量的数据，当并发量很高的时候，会遇到内存、并发、存储等的瓶颈，因此需要真正的分布式架构来进行负载均衡。 简介cluster模式实现了Redis数据的分布式存储，实现数据的分片，每个redis节点存储不同的内容，并且解决了在线的节点收缩（下线）和扩容（上线）问题。 redis cluster 主要基于 CRC16 算法对 key 进行 hash ，然后散列到不同散列槽。redis cluster 总共提供 16384 个hash 槽(slot) ，理论上，集群的最大节点数量最大为 16384 个。不过 redis 官方给出的建议是不要超过 1000 的量级。每个 redis instance 会负责这个散列槽中的一部分。新增或删除节点，对于 redis cluster 而言就是对 slot 进行 reshard，redis cluster 保证 slot 平滑移动。 优点：无中心节点（所有Redis节点都是对等的节点，同步数据使用的是Gossip协议），数据按照槽存储分布在多个 Redis 实例上，可以平滑的进行节点 扩容/缩容，当节点数量改变时，只需要动态更改节点负责的槽就行，这对于客户端来说是透明的。不需要依赖中间件，运维成本低。 缺点：严重依赖 Redis-trib 工具，缺乏监控管理，Failover节点的检测过慢，Gossip协议传播消息到最终一致性有一定的延迟。 通信机制Redis cluster 节点间采用 gossip 协议进行通信。 gossip协议gossip协议包含多种消息，包含 ping , pong , meet , fail 等等。 meet：某个节点发送 meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。 ping：每个节点都会频繁给其它节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。 pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。 fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机 分布式寻址算法 hash算法 一致性hash算法 hash slot算法（redis cluster采用） Redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。 Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。 任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。 高可用与主备切换原理Redis cluster 的高可用的原理，几乎跟哨兵是类似的。 判断节点宕机 从节点过滤 从节点选举 相比哨兵模式，Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。 cluster环境搭建 redis 集群一般由多个节点组成，节点数量至少为6个，才能保证组成 完整高可用的集群。每个节点需要开启配置 cluster-enabled yes，让 redis 运行在集群模式下。 因此搭建三主三从，主服务分别为7000,7001,7002，从服务分别为7003,7004,7005。如下图所示。 配置文件编辑redis.conf文件，复制5份，将其中的7000进行替换修改，主要配置如下： 12345678910111213port 7000daemonize yespidfile /home/redis/tmp/scripts-redis/cluster/pid/pid_7000.pidbind 127.0.0.1loglevel noticelogfile /home/redis/tmp/scripts-redis/cluster/log/log_7000.logdbfilename \"dump.rdb\"dir \"/home/redis/tmp/scripts-redis/cluster/data/7000\"cluster-enabled yescluster-config-file \"/home/redis/tmp/scripts-redis/cluster/config/nodes_7000.conf\"cluster-node-timeout 5000 启动服务123456/usr/local/bin/redis-server redis7000.conf /usr/local/bin/redis-server redis7001.conf /usr/local/bin/redis-server redis7002.conf /usr/local/bin/redis-server redis7003.conf /usr/local/bin/redis-server redis7004.conf /usr/local/bin/redis-server redis7005.conf 启动命令后结果如下图所示。 创建集群1redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1 执行命令后，输出如下图所示。 集群验证以集群模式连接客户端，并设置key。 12345678910[root@VM_0_4_centos bin]# redis-cli -c -p 7000127.0.0.1:7000&gt; set a b-&gt; Redirected to slot [15495] located at 127.0.0.1:7002OK127.0.0.1:7002&gt; set short short-&gt; Redirected to slot [2103] located at 127.0.0.1:7000OK127.0.0.1:7000&gt; get short\"short\"127.0.0.1:7000&gt; 将7000端口的主服务停掉，可以看到原来存储在7000里的key自动存储到7005上，同时cluster自动切换主服务到7005。 12345678910111213127.0.0.1:7000&gt; shutdownnot connected&gt; [root@VM_0_4_centos bin]# redis-cli -c -p 7000Could not connect to Redis at 127.0.0.1:7000: Connection refusednot connected&gt; set a b [EX seconds|PX milliseconds] [NX|XX] [KEEPTTL][root@VM_0_4_centos bin]# redis-cli -c -p 7001127.0.0.1:7001&gt; get short-&gt; Redirected to slot [2103] located at 127.0.0.1:7005\"short\"127.0.0.1:7005&gt; get name-&gt; Redirected to slot [5798] located at 127.0.0.1:7001\"hello\"127.0.0.1:7001&gt; 12345678910111213127.0.0.1:7005&gt; info replication# Replicationrole:masterconnected_slaves:0master_replid:5b3a8ba01eb3c6afa931cb6143a72340f283e48cmaster_replid2:47821ec4918bb29baa1f4546f4111f57af88efaamaster_repl_offset:1107second_repl_offset:1108repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1107127.0.0.1:7005&gt; 总结Redis实现高可用，支持三种集群模式：主从模式、哨兵模式以及cluster模式。 其中cluster模式是最好用的，推荐使用。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/tags/Redis/"},{"name":"高可用","slug":"高可用","permalink":"http://geekvic.top/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"cluster","slug":"cluster","permalink":"http://geekvic.top/tags/cluster/"},{"name":"主从复制","slug":"主从复制","permalink":"http://geekvic.top/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"哨兵","slug":"哨兵","permalink":"http://geekvic.top/tags/%E5%93%A8%E5%85%B5/"}]},{"title":"Redis持久化怎么玩","slug":"redis持久化怎么玩","date":"2020-07-10T06:00:00.000Z","updated":"2020-07-10T07:09:55.527Z","comments":true,"path":"post/758625c3.html","link":"","permalink":"http://geekvic.top/post/758625c3.html","excerpt":"什么是持久化？将数据保存到可永久保存的存储设备中，持久化的主要应用是将内存中的对象存储到数据库中，或者存储到磁盘文件中、XML数据文件中等。 也可以这样理解持久化： 应用层：如果关闭( Close )你的应用，然后重新启动则先前的数据依然存在。 系统层：如果关闭( Shut Down )你的系统(电脑)，然后重新启动则先前的数据依然存在。 为何要持久化？Redis的数据是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据会丢掉，因此为了让数据能够长期保存，就要将Redis里的数据做持久化存储。","text":"什么是持久化？将数据保存到可永久保存的存储设备中，持久化的主要应用是将内存中的对象存储到数据库中，或者存储到磁盘文件中、XML数据文件中等。 也可以这样理解持久化： 应用层：如果关闭( Close )你的应用，然后重新启动则先前的数据依然存在。 系统层：如果关闭( Shut Down )你的系统(电脑)，然后重新启动则先前的数据依然存在。 为何要持久化？Redis的数据是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据会丢掉，因此为了让数据能够长期保存，就要将Redis里的数据做持久化存储。 持久化有哪几种？Redis为持久化提供了两种方式： RDB每隔N分钟或N次操作，从内存dump数据形成rdb文件，压缩，放在备份目录，主要是以快照的方式进行保存。 AOF记录每次对redis的命令操作，有点类似记录操作日志，当服务器重启的时候会重新执行这些命令来恢复原始数据。 持久化配置RDB持久化配置1234567891011121314#时间策略save 900 1 #900秒至少有一个变化，则dumpsave 300 10 #300秒至少有10个变化，则dumpsave 60 10000 #60秒至少有10000个变化，则dumpstop-writes-on-bgsave-error yes #如果持久化出错，主程序是否停止写入rdbcompression yes #是否支持压缩rdbchecksum yes #存储和加载rdb文件时是否校验dbfilename dump.rdb #设置rdb文件名dir /usr/local/data #rdb文件保存路径 如果想禁用RDB配置，在save的最后一行写上：save “” AOF持久化配置123456789101112131415appendonly yes #是否开启aof，默认noappendfilename \"appendonly.aof\" #文件名称appendfsync everysec #同步方式no-appendfsync-on-rewrite no #aof重写期间是否不同步#重写触发配置auto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小增长率100%时重写auto-aof-rewrite-min-size 64mb #aof文件至少64M时重写aof-load-truncated yes #加载aof时如果有出错的处理aof-use-rdb-preamble yes #文件重写策略 appendfsync有三种模式： always：每一个命令都同步到aof，安全，速度慢。 no： 由操作系统判断缓冲区大小，统一写入到aof，同步频率低，速度快。 everysec：折中方案，每秒写一次，最多丢一秒。 aof-load-truncated yes 如果配置启用，在加载时如果发现aof尾部不正确时，会向客户端写入一个log，但是会继续执行，如果设置为no，发现错误就会停止，必须修复后才能重新加载。 持久化工作原理RDB工作原理RDB持久化触发分为两种：自己手动触发与Redis定时触发。 手动触发 save：会阻塞当前redis服务器，直到持久化完成，线上应该禁止使用。 bgsave：该触发方式会fork一个子进程，由于进程负责持久化过程，因此阻塞只会发生在fork子进程的时候 自动触发 根据 save m n配置规则自动触发 从节点全量复制时，主节点发送rdb文件给从节点完成复制操作，主节点会触发bgsave 执行 debug reload时； 执行shutdown时，如果没有开启aof，也会触发 AOF工作原理主要分为两步： 命令的实时写入，如果是appendfsync everysec配置，会有1s损耗 对aof文件重写 aof重写是为了减少aof文件的大小，可以手动或者自动触发。 手动触发：bgrewriteof 自动触发：根据配置规则触发，当然自动触发的整体时间还跟Redis的定时任务频率有关系 持久化恢复数据如果一台服务器上既有RDB文件，又有AOF文件，加载哪个呢？ 如果想要恢复数据，只要重启Redis即可。启动时会检查AOF文件是否存在，如果不存在就尝试加载RDB。优先加载AOF的原因是AOF保存的数据更完整，我们知道AOF基本上最多丢失1s的数据。如下图所示。 性能优化建议 如果Redis数据并不是很重要或者可以通过其他方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其他途径补回 自定义策略定期检查Redis情况，然后可以手动触发备份、重写数据 单机如果部署多个实例，要防止多个实例同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变成串行 可以配置主从复制，利用一台从服务器进行备份处理，其他机器正常响应客户端的命令 RDB持久化与AOF持久化可以同时存在，配合使用。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/categories/Redis/"}],"tags":[{"name":"持久化","slug":"持久化","permalink":"http://geekvic.top/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"Redis基本命令","slug":"redis基本命令","date":"2020-07-10T03:30:00.000Z","updated":"2020-07-10T07:09:55.526Z","comments":true,"path":"post/76b87db6.html","link":"","permalink":"http://geekvic.top/post/76b87db6.html","excerpt":"启动Redis，打开客户端12./redis-server /etc/redis.conf ./redis-cli 通用命令 命令 解释 get key 查询key set key value 设置key keys * *通配多个字符 keys key 获取名字为key的key keys ?ey 通配单个字符 keys k[eio]y 通配括号内的某一个字符 randomkey 随机返回key type key 返回存储类型 exists key 判断key是否存在 del key 删除key rename key newkey 修改key名称 renamenx key newkey 如果存在修改失败，如果不存在则修改成功 select n 切换到redis数据库，默认16个，从0开始编号 expire key 时间（s） 设置有效期 ttl key 查询有效期（-1是永久有效 -2不存在的key） persist key 设置永久有效 字符串命令 命令 解释 set key value ex 秒数 或 px 毫秒数 过期时间 mset key1 value1 key2 value2 key3 value3 一次设置多个值 mget key1 key2 key3 一次获取多个值 getset key newvalue 返回上一个值，同时修改当前为新值 incr key 增加 decr key 减少 incrby key num 增加某个num decrby key num 减少某个num 列表命令","text":"启动Redis，打开客户端12./redis-server /etc/redis.conf ./redis-cli 通用命令 命令 解释 get key 查询key set key value 设置key keys * *通配多个字符 keys key 获取名字为key的key keys ?ey 通配单个字符 keys k[eio]y 通配括号内的某一个字符 randomkey 随机返回key type key 返回存储类型 exists key 判断key是否存在 del key 删除key rename key newkey 修改key名称 renamenx key newkey 如果存在修改失败，如果不存在则修改成功 select n 切换到redis数据库，默认16个，从0开始编号 expire key 时间（s） 设置有效期 ttl key 查询有效期（-1是永久有效 -2不存在的key） persist key 设置永久有效 字符串命令 命令 解释 set key value ex 秒数 或 px 毫秒数 过期时间 mset key1 value1 key2 value2 key3 value3 一次设置多个值 mget key1 key2 key3 一次获取多个值 getset key newvalue 返回上一个值，同时修改当前为新值 incr key 增加 decr key 减少 incrby key num 增加某个num decrby key num 减少某个num 列表命令 命令 解释 lpush key value 左侧插入 rpush key value 右侧插入 lrange key start stop 取出值（范围） lpop 从左侧弹出 rpop 从右侧弹出 lrem key count value 删除指定count的value ltrim key start stop 截取链表中某一段 lindex key index 返回链表某个索引对应的值 linsert key before或after pivot element 在某个值的前或者后插入某个值 集合命令 命令 解释 sadd key value1 value2 新增 smembers key 查看集合的元素 srem key value 删除集合 spop key 随机弹出一个元素并删除 sismember gender value 判断value是否在集合中 scard key 计算集合大小 sunion key1 key2 求并集 sinter key1 key2 求交集 sdiff key1 key2 求差集 有序集合命令 命令 解释 zadd key score1 value1 score2 value2 新增 zrange key start stop 取元素 zrangebyscore key min max 通过分数取元素 zrank key member 查看排名 Hash命令 命令 解释 hset key field1 value1 field2 value2 新增 hgetall key 查询 hget key field 查询某个域 hdel key field 删除 运维命令 命令 解释 time 查看时间戳与微秒数 dbsize 查看当前库中的key数量 bgrewriteaof aof重写 bgsave 保存rdb快照 flushall 清空所有库 flushdb 清空当前库 info redis的基本信息 config get/set 获取/设置配置信息 slowlog get 慢日志查询 shutdown 停止所有客户端，关闭redis服务器 Redis事务 命令 解释 multi 开启事务，放到队列里 exec 执行事务 discard 取消事务 watch 监控、加锁 Redis频道发布与消息订阅 命令 解释 publish 发布 subscribe 订阅 psubscribe 订阅支持通配符","categories":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/tags/Redis/"}]},{"title":"Linux下安装新版本Redis遇到的坑","slug":"linux下安装新版本redis遇到的坑","date":"2020-07-09T02:00:00.000Z","updated":"2020-07-09T02:50:44.170Z","comments":true,"path":"post/755670ae.html","link":"","permalink":"http://geekvic.top/post/755670ae.html","excerpt":"什么是Redis？Remote Dictionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 与传统数据库不同的是 Redis 的数据是存在内存中的，所以存写速度非常快，因此 Redis 被广泛应用于缓存方向。 数据类型有哪些？它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 安装","text":"什么是Redis？Remote Dictionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 与传统数据库不同的是 Redis 的数据是存在内存中的，所以存写速度非常快，因此 Redis 被广泛应用于缓存方向。 数据类型有哪些？它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 安装下载官网下载最新版本，并解压到/usr/local，并将文件夹重命名为redis 遇到的坑执行make命令时遇到的报错 123make[1]: *** [server.o] 错误 1make[1]: 离开目录“/usr/local/redis/src”make: *** [all] 错误 2 解决方法，升级gcc版本 1234gcc -v yum -y install centos-release-sclyum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilsscl enable devtoolset-9 bash 再次make，安装成功后，Hint: It’s a good idea to run ‘make test’ 查看安装目录 1cd /usr/local/bin redis-benchmark 性能测试工具 redis-check-aof 检查aof日志工具 redis-check-rdb 检查rdb日志工具 redis-cli redis客户端 redis-server redis服务端 redis-sentinel redis哨兵服务","categories":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/tags/Redis/"}]},{"title":"Hexo进阶设置","slug":"Hexo进阶设置","date":"2020-05-20T08:57:00.000Z","updated":"2020-05-22T06:12:48.239Z","comments":true,"path":"post/a62b0c3d.html","link":"","permalink":"http://geekvic.top/post/a62b0c3d.html","excerpt":"部署平台选型前言GitHub和Gitee（码云）是国内外比较流行的代码托管平台，现都推出GitHub/Gitee Pages可以存放静态网页代码，因此可以用来搭建自己的博客。 优缺点 平台 优点 缺点 Github 全球最流行的平台，且免费 国内由于有墙，访问太慢 Gitee 国内访问快 阉割部分功能，提供有偿服务，比如自动部署、自定义域名等需要升级Gitee Pages Pro 如上图所示，Gitee是需要付费的，但是考虑到部署到Github上，在国内访问真的太慢，经常加载要十几秒，最终折中了选择，即两个平台同时部署，国外的用户可以访问Github，国内的用户访问Gitee，从而优化访问速度。","text":"部署平台选型前言GitHub和Gitee（码云）是国内外比较流行的代码托管平台，现都推出GitHub/Gitee Pages可以存放静态网页代码，因此可以用来搭建自己的博客。 优缺点 平台 优点 缺点 Github 全球最流行的平台，且免费 国内由于有墙，访问太慢 Gitee 国内访问快 阉割部分功能，提供有偿服务，比如自动部署、自定义域名等需要升级Gitee Pages Pro 如上图所示，Gitee是需要付费的，但是考虑到部署到Github上，在国内访问真的太慢，经常加载要十几秒，最终折中了选择，即两个平台同时部署，国外的用户可以访问Github，国内的用户访问Gitee，从而优化访问速度。 修改_config.yml12345deploy: type: git repo: github: git@github.com:[username]/[username].github.io.git,master gitee: git@gitee.com:[username]/[username].git,master 其中，这里的 username指的是你在这两个网站上的用户名，只有以这种命名形式的仓库，才能够来访问我们的博客。 Github的仓库名要命名为：{username}.github.io Gitee的仓库名要命名为：{username} 比如说，我的Github和Gitee的username是geekvic，那么在部署博客成功后，我就可以通过下边的url来访问我的Hexo博客： http://geekvic.github.io/ http://geekvic.gitee.io/ 主题选择Hexo主题地址：https://hexo.io/themes/， 我们可以去挑选自己喜欢的主题，每个主题在github上面都开源了源码，下面主要以我选择的theme-next主题进行介绍。 找到Hexo文件的目录,如下图所示。 进入theme文件夹，执行命令 1git clone https://github.com/theme-next/hexo-theme-next.git 下载完成后，则会在themes文件夹下出现一个新的名为hexo-theme-next的文件夹，这就是我们刚下载的主题，返回hexo站点的配置文件_config.yml，修改配置： 1theme: hexo-theme-next 再执行下命令，就可以看到更改后的主题 123hexo clean //清除一下缓存hexo g //生成静态页面hexo s //开启本地服务器 Hexo基础设置配置网站基础信息修改站点配置文件_config.yml中，修改： 12345678# Sitetitle: # 网站标题subtitle: # 网站副标题description: # 描述，介绍网站的keywords: # 网站的关键字author: # 博主姓名language: zh-CN # 语言：zh-CN 是简体中文timezone: # 时区 Next主题进阶设置配置主题 默认的主题配置文件_config.yml中，菜单只开启了首页和归档，我们根据需要，可以添加 about、tag、categories 等菜单 123456menu: home: / || fa fa-home about: /about/ || fa fa-user tags: /tags/ || fa fa-tags categories: /categories/ || fa fa-th archives: /archives/ || fa fa-archive 增加about页面进入Hexo目录，执行hexo new page “about”，会发现在source目录下多了个about目录，在里面的index.md写入内容 增加tag页面1234567hexo new page \"tags\"vim source/tags/index.md---title: 标签date: 2020-05-20 17:06:19type: tags--- 增加categories页面1234567hexo new page \"categories\"vim source/tags/index.md---title: 分类date: 2020-05-20 17:06:19type: \"categories\"--- 配置 hexo 中 next 主题样式选择Next 一共提供了 4 种首页样式，按照自己喜好选择一个，我使用的是Gemini 12345# Schemes#scheme: Muse#scheme: Mist#scheme: Piscesscheme: Gemini 配置footer信息1234567891011121314151617footer: since: 2020 # 建站开始时间 icon: name: heart # 设置 建站初始时间和至今时间中间的图标，默认是一个'小人像'，更改user为heart可以变成一个心 animated: true color: \"#ff0000\" # 更改图标的颜色为红色 #显示版权作者 copyright: vic powered: enable: true # 开启hexo驱动显示 version: true # 开启hexo版本号 theme: enable: true # 开启主题驱动 version: true # 开启主题版本号 beian: enable: true # 开启备案号显示 icp: 苏ICP备... # 备案号 配置头像信息12345678# Sidebar Avataravatar: # Replace the default image and set the url here. url: /images/jin.png # If true, the avatar will be dispalyed in circle. rounded: false # If true, the avatar will be rotated with the cursor. rotated: true 配置社交信息和友链12345678social: GitHub: https://github.com/yourname || github E-Mail: mailto:yourname@gmail.com || envelopesocial_icons: enable: true # 显示社交图标 # 仅显示图标 icons_only: true # 只显示图标，不显示文字 transition: true # 动画效果 首页文章属性1234567post_meta: item_text: true # 可以一行显示，文章的所有属性 created_at: true # 显示创建时间 updated_at: enabled: true # 显示修改的时间 another_day: true # 设true时，如果创建时间和修改时间一样则显示一个时间 categories: true # 显示分类信息 开启文章目录123456toc: #侧栏中的目录 enable: true #是否自动生成目录 number: true #目录是否自动产生编号 wrap: false #标题过长是否换行 expand_all: false max_depth: 6 #最大标题深度 Follow me on GitHub1234github_banner: enable: true permalink: https://github.com/yourname title: Follow me on GitHub 字数统计、阅读时长 首先安装插件： 1$ npm install hexo-symbols-count-time --save 主题配置文件修改如下： 123456symbols_count_time: separated_meta: true # 统计信息不换行显示 item_text_post: true # 文章统计信息中是否显示“本文字数/阅读时长”等描述文字 item_text_total: false # 底部footer站点统计信息中是否显示“本文字数/阅读时长”等描述文字 awl: 4 # 平均字符长度 wpm: 275 # 阅读速度, 一分钟阅读的字数 站点配置文件 新增如下： 12345678# 新增文章字数统计symbols_count_time: #文章内是否显示 symbols: true # 文章字数 time: true # 阅读时长 # 网页底部是否显示 total_symbols: false # 所有文章总字数 total_time: false # 所有文章阅读中时长 显示当前浏览进度 右下角显示文章当前浏览进度，提供意见置顶功能，编辑主题配置文件，配置如下： 1234back2top: enable: true #是否提供一键置顶 sidebar: false scrollpercent: true # 是否显示当前阅读进度 阅读进度 Next主题支持页面滚动阅读进度指示器。 编辑主题配置文件，配置如下: 12345reading_progress: enable: true position: top color: \"#37c6c0\" height: 3px 设置代码高亮主题 Next 默认使用的是 白色的 normal 主题，可选的值有 normal，night， night blue， night bright， night eighties 123456codeblock: highlight_theme: normal copy_button: enable: true # 显示复制按钮 show_result: true style: mac #按钮样式: default | flat | mac 本地搜索插件安装插件1$ npm install hexo-generator-searchdb --save 修改站点配置文件，添加如下内容：123456# 本地搜索search: path: search.xml field: post format: html limit: 10000 path：索引文件的路径，相对于站点根目录 field：搜索范围，默认是 post，还可以选择 page、all，设置成 all 表示搜索所有页面 limit：限制搜索的条目数 修改主题配置文件12345678# Local Search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search: enable: true trigger: auto top_n_per_article: 1 #每篇文章中显示的搜索数量 unescape: false preload: false 数据分析与统计 Next内置了leancloud、firebase、busuanzi三种访客统计插件，前两种需要到官网注册获取网站颁发的appKey，相对麻烦。而不蒜子配置只需要将false改为true即可: 1234567891011busuanzi_count: enable: true # 总访客数 total_visitors: true total_visitors_icon: user # 总浏览量 total_views: true total_views_icon: eye # 文章浏览量 post_views: true post_views_icon: eye","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/tags/Hexo/"},{"name":"Next","slug":"Next","permalink":"http://geekvic.top/tags/Next/"}]},{"title":"Hexo如何快速搭建个人博客","slug":"hexo如何快速搭建个人博客","date":"2020-05-19T08:00:00.000Z","updated":"2020-05-22T06:12:48.247Z","comments":true,"path":"post/e48abe66.html","link":"","permalink":"http://geekvic.top/post/e48abe66.html","excerpt":"什么是Hexo?Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 优势 Node.js 所带来的超快生成速度，让上百个页面在几秒内瞬间完成渲染。 Hexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件。 只需一条指令即可部署到 GitHub Pages,Gitee Pages, Heroku 或其他平台。 强大的 API 带来无限的可能，与数种模板引擎（EJS，Pug，Nunjucks）和工具（Babel，PostCSS，Less/Sass）轻易集成 如何安装？安装Hexo前需要先安装Node.js和Git，支持windows、Mac、Linux安装，本文主要介绍在如何在Linux上安装 安装Git","text":"什么是Hexo?Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 优势 Node.js 所带来的超快生成速度，让上百个页面在几秒内瞬间完成渲染。 Hexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件。 只需一条指令即可部署到 GitHub Pages,Gitee Pages, Heroku 或其他平台。 强大的 API 带来无限的可能，与数种模板引擎（EJS，Pug，Nunjucks）和工具（Babel，PostCSS，Less/Sass）轻易集成 如何安装？安装Hexo前需要先安装Node.js和Git，支持windows、Mac、Linux安装，本文主要介绍在如何在Linux上安装 安装Git执行命令1sudo yum install git-core 查看是否安装完毕，若显示版本信息，表示安装成功1git --version 配置用户名、邮箱12git config --global user.email \"zhangviv@163.com\"git config --global user.name \"vic\" ssh设置12ssh-keygen -t rsa -C \"zhangviv@163.com\"cd /root/.ssh 查看用户目录下是否有文件，并将id_rsa.pub内容加到github、gitee等工具的公钥配置里1id_rsa id_rsa.pub known_hosts 安装Node.js官网下载最新版本 解压1tar -xvf node-v12.16.3-linux-x64.tar.xz 进入bin，查看是否安装成功1./node -v node、npm创建软链接，执行命令12ln -s /home/software/node-v12.16.3-linux-x64/bin/node /usr/local/bin/node ln -s /home/software/node-v12.16.3-linux-x64/bin/npm /usr/local/bin/npm 进入/usr/local/bin下查看文件是否生成1node npm 再次查看软连接是否成功，如何显示版本，则node.js安装成功 安装Hexo所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。1npm install -g hexo-cli hexo创建软连接1ln -s /home/software/node-v12.16.3-linux-x64/bin/hexo /usr/local/bin/hexo 创建博客文件夹，下载资源123mkdir blogcd blog hexo init //会自动把资源文件下载好 启动测试，输入localhost:4000，即可访问本地的博客测试地址1hexo s Hexo常用命令清除缓存命令1hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令 启动测试1hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 生成静态文件1hexo g 全写命令是： 1hexo generate 部署网站1hexo d 全写命令是： 1hexo deploy","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/tags/Hexo/"},{"name":"Git","slug":"Git","permalink":"http://geekvic.top/tags/Git/"},{"name":"node.js","slug":"node-js","permalink":"http://geekvic.top/tags/node-js/"}]},{"title":"如何用Docker部署Spring Boot项目","slug":"如何用Docker部署Spring Boot项目","date":"2019-12-15T12:36:00.000Z","updated":"2020-05-22T06:12:48.251Z","comments":true,"path":"post/904ba16.html","link":"","permalink":"http://geekvic.top/post/904ba16.html","excerpt":"1.idea中安装docker插件；2.新建DockerFile，内容如下。123456789101112# 基础镜像使用javaFROM java:8# 作者MAINTAINER vic &lt;test@163.com&gt;# VOLUME 指定了临时文件目录为/tmp。# 其效果是在主机 /var/lib/docker 目录下创建了一个临时文件，并链接到容器的/tmpVOLUME /tmp# 将jar包添加到容器中并更名为app.jarADD es-1.0.0-SNAPSHOT.jar app.jar# 运行jar包RUN bash -c 'touch /app.jar'ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app.jar\"] 3.将es-1.0.0-SNAPSHOT.jar以及DockerFile放到一个目录中，执行命令，生成docker镜像。1docker build -t es:1.0.0 -f DockerFile . 4.查看当前的镜像 docker images，并运行镜像，启动容器。1docker run -d -p 8081:8081 es:1.0.0","text":"1.idea中安装docker插件；2.新建DockerFile，内容如下。123456789101112# 基础镜像使用javaFROM java:8# 作者MAINTAINER vic &lt;test@163.com&gt;# VOLUME 指定了临时文件目录为/tmp。# 其效果是在主机 /var/lib/docker 目录下创建了一个临时文件，并链接到容器的/tmpVOLUME /tmp# 将jar包添加到容器中并更名为app.jarADD es-1.0.0-SNAPSHOT.jar app.jar# 运行jar包RUN bash -c 'touch /app.jar'ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app.jar\"] 3.将es-1.0.0-SNAPSHOT.jar以及DockerFile放到一个目录中，执行命令，生成docker镜像。1docker build -t es:1.0.0 -f DockerFile . 4.查看当前的镜像 docker images，并运行镜像，启动容器。1docker run -d -p 8081:8081 es:1.0.0 5.若想进入当前的容器1docker exec -it containerId /bin/bash 6.查看开放的端口1netstat -ntpl 7.查看spring boot应用的日志1docker logs -f --tail=1000 containerId","categories":[{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://geekvic.top/tags/Docker/"}]},{"title":"从零搭建基于Prometheus+Grafana+AlertManager的监控报警系统","slug":"从零搭建基于Prometheus+Grafana+AlertManager的监控报警系统","date":"2019-12-10T08:42:00.000Z","updated":"2020-09-04T03:12:23.406Z","comments":true,"path":"post/c795510d.html","link":"","permalink":"http://geekvic.top/post/c795510d.html","excerpt":"前言 业务中是否经常遇到服务器负载过高问题，或者经常碰到后台服务挂掉，却没有自动提醒功能，因此搭建一套监控报警系统势在必行。 Prometheus目前在开源社区相当活跃，在GitHub上拥有两万多Star，是当前最流行的监控系统，相比Zabbix，定制灵活度更高，而且Prometheus在云环境、容器支持这块优势明显。 Prometheus简介Prometheus是一套开源的监控&amp;报警&amp;时间序列数据库的组合，基于应用的metrics来进行监控的开源工具。 下载&amp;安装","text":"前言 业务中是否经常遇到服务器负载过高问题，或者经常碰到后台服务挂掉，却没有自动提醒功能，因此搭建一套监控报警系统势在必行。 Prometheus目前在开源社区相当活跃，在GitHub上拥有两万多Star，是当前最流行的监控系统，相比Zabbix，定制灵活度更高，而且Prometheus在云环境、容器支持这块优势明显。 Prometheus简介Prometheus是一套开源的监控&amp;报警&amp;时间序列数据库的组合，基于应用的metrics来进行监控的开源工具。 下载&amp;安装 下载地址：https://prometheus.io/download/ 解压：tar zxvf prometheus-2.12.0.linux-amd64.tar.gz 编辑： prometheus.yml，其中包括全局、alertmanager、告警规则、监控job配置，具体内容如下。 123456789101112131415161718192021222324252627282930313233343536373839# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: - 192.168.88.69:9093# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: - \"test_rules.yml\" # - \"second_rules.yml\"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['192.168.88.69:9090'] - job_name: 'monitor' scrape_interval: 5s metrics_path: '/actuator/prometheus' static_configs: - targets: ['192.168.88.69:8008'] - job_name: 'node-exporter' static_configs: - targets: ['192.168.88.69:9100'] 启动：./prometheus &amp; 验证安装：访问地址：http://192.168.88.69:9090/targets Spring Boot集成Prometheus配置pom文件123456789&lt;!--监控--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; 配置yml12345678910111213server: port: 8008spring: application: name: monitormanagement: endpoints: web: exposure: include: '*' metrics: tags: application: $&#123;spring.application.name&#125; 添加配置类1234567@Configurationpublic class MeterRegistryConfig &#123; @Bean MeterRegistryCustomizer&lt;MeterRegistry&gt; configurer(@Value(\"$&#123;spring.application.name&#125;\") String applicationName) &#123; return (registry) -&gt; registry.config().commonTags(\"application\", applicationName); &#125;&#125; AlertManager简介Alertmanager 对收到的告警信息进行处理，包括去重，降噪，分组，策略路由告警通知。 配置修改alertmanager.yml，当前配置的是邮箱告警，当然还支持企业微信、钉钉等，内容如下： 12345678910111213141516171819global: resolve_timeout: 5m smtp_smarthost: 'smtp.mxhichina.com:25' # smtp地址 smtp_from: 'test@163.com' # 发送邮箱地址 smtp_auth_username: 'test@163.com' # 邮箱用户 smtp_auth_password: '123456' # 邮箱密码route: group_by: [\"instance\"] # 分组名 group_wait: 10s # 当收到告警的时候，等待十秒看是否还有告警，如果有就一起发出去 igroup_interval: 10s # 发送警告间隔时间 repeat_interval: 1h # 重复报警的间隔时间 receiver: mail # 全局报警组，这个参数是必选的，和下面报警组名要相同receivers:- name: 'mail' # 报警组名 email_configs: - to: 'receiver@163.com' # 收件人邮箱 headers: &#123;Subject: \"告警测试邮件\"&#125; 启动命令：./alertmanager &amp; ，端口号：9093 Grafana简介Grafana是一款用Go语言开发的开源数据可视化工具，可以做数据监控和数据统计，带有告警功能。 配置 解压grafana-6.3.5.linux-amd64.tar.gz，启动 ./grafana-server &amp;，访问地址http://192.168.88.69:3000 配置Data Sources 安装exporter，如要监控服务器的运行状态，需要安装node_exporter，并启动项目，端口号：9100，并在prometheus里配置节点，并重启prometheus。 导入模板，可以在Grafana官网找下，地址：https://grafana.com/grafana/dashboards。","categories":[{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://geekvic.top/tags/prometheus/"},{"name":"grafana","slug":"grafana","permalink":"http://geekvic.top/tags/grafana/"},{"name":"alertmanager","slug":"alertmanager","permalink":"http://geekvic.top/tags/alertmanager/"}]},{"title":"手把手教你如何搭建ELK日志收集系统","slug":"手把手教你如何搭建ELK日志收集系统","date":"2019-11-27T06:46:00.000Z","updated":"2020-09-07T07:58:02.000Z","comments":true,"path":"post/5c1c8f0.html","link":"","permalink":"http://geekvic.top/post/5c1c8f0.html","excerpt":"ELK简介 你还在为线上排查日志找不到节点服务器而犯愁吗？今天手把手教大家如何搭建一套日志收集系统，用来代替传统的人工登录服务器查看后台服务日志的方式。 在传统项目中，如果在生产环境中，有多台不同的服务器集群，如果生产环境需要通过日志定位项目的Bug的话，需要在每台节点上使用传统的命令方式查询，这样效率非常低下。因此我们需要集中化的管理日志，ELK则应运而生。ELK=ElasticSeach+Logstash+Kibana，日志收集原理如下所示。 每台服务器集群节点安装Logstash日志收集系统插件 每台服务器节点将日志输入到Logstash中 Logstash将该日志格式化为json格式，根据每天创建不同的索引，输出到ElasticSearch中 浏览器使用安装Kibana查询日志信息&nbsp; Elastic Search简介","text":"ELK简介 你还在为线上排查日志找不到节点服务器而犯愁吗？今天手把手教大家如何搭建一套日志收集系统，用来代替传统的人工登录服务器查看后台服务日志的方式。 在传统项目中，如果在生产环境中，有多台不同的服务器集群，如果生产环境需要通过日志定位项目的Bug的话，需要在每台节点上使用传统的命令方式查询，这样效率非常低下。因此我们需要集中化的管理日志，ELK则应运而生。ELK=ElasticSeach+Logstash+Kibana，日志收集原理如下所示。 每台服务器集群节点安装Logstash日志收集系统插件 每台服务器节点将日志输入到Logstash中 Logstash将该日志格式化为json格式，根据每天创建不同的索引，输出到ElasticSearch中 浏览器使用安装Kibana查询日志信息&nbsp; Elastic Search简介ElasticSearch是一个分布式搜索服务，提供的是一组Restful API，底层基于Lucene，采用多shard（分片）的方式保证数据安全，并且提供自动resharding的功能。是目前全文搜索引擎的首选，可以快速的存储、搜索和分析海量数据。 安装 官网下载最新版本，地址是：https://www.elastic.co/cn/downloads/elasticsearch，下载下来的最新版本是：elasticsearch-7.4.2-linux-x86_64.tar.gz； 解压：# tar zxvf elasticsearch-7.4.2-linux-x86_64.tar.gz 命令：#cd elasticsearch-7.4.2，配置config里的elasticsearch.yml文件，配置如下。 12345678cluster.name: es-applicationnode.name: es-node-1network.host: 0.0.0.0http.port: 9200discovery.seed_hosts: [\"192.168.1.169\"]cluster.initial_master_nodes: [\"es-node-1\"]path.data: /var/data/espath.logs: /var/log/es 常见问题（1）can not run elasticsearch as root 解决思路：为了安全不允许使用root用户启动，需要新建一个es的账户，如下所示。 123456# adduser es# passwd es# chown -R es elasticsearch-7.4.2 # su elasticsearch启动ES：# ./bin/elasticsearch （2）max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 解决思路：切换到root用户修改# vim /etc/security/limits.conf，在最后面追加下面内容，其中es 是启动ES的用户，不是root。 12es hard nofile 65536es soft nofile 65536 （3）max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决思路：切换到root用户修改配置sysctl.conf 12345#vi /etc/sysctl.conf添加下面配置：vm.max_map_count=655360并执行命令：sysctl -p 启动12后台启动：./elasticsearch -d停止命令：./elasticsearch -stop 验证访问 ip:9200，成功显示如下json信息 ES Head推荐安装chrome插件，也可以下载安装包进行安装。 Logstash简介Logstash 是一个完全开源的工具，它可以对你的日志进行收集、过滤、分析，支持大量的数据获取方法，并将其存储供以后使用（如搜索）。 安装与配置 解压logstash-7.4.2，修改logstash-7.4.2/config的logstash.conf文件； logstash.conf文件配置如下： 1234567891011121314input &#123;tcp &#123;mode =&gt; \"server\"host =&gt; \"192.168.1.169\"port =&gt; 4560codec =&gt; json_lines&#125;&#125;output &#123;elasticsearch &#123;hosts =&gt; \"192.168.1.169:9200\"index =&gt; \"springboot-logstash-%&#123;+YYYY.MM.dd&#125;\"&#125;&#125; 执行命令 1# ../bin/logstash -f logstash.conf Spring boot集成Logstashpom文件里引入jar包123456&lt;!--logstash--&gt;&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;6.2&lt;/version&gt;&lt;/dependency&gt; 修改logback-spring.xml123456789101112131415161718192021222324252627282930&lt;!--logstash地址--&gt;&lt;springProperty scope=\"context\" name=\"LOGSTASH_ADDRESS\" source=\"logstash.address\"/&gt;&lt;!--输出到logstash的appender--&gt;&lt;appender name=\"LOGSTASH\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt;&lt;!--可以访问的logstash日志收集端口--&gt;&lt;destination&gt;$&#123;LOGSTASH_ADDRESS&#125;&lt;/destination&gt;&lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt;&lt;providers&gt;&lt;timestamp&gt;&lt;timeZone&gt;UTC&lt;/timeZone&gt;&lt;/timestamp&gt;&lt;pattern&gt;&lt;pattern&gt;&#123;\"app\": \"java-study\",\"level\": \"%-5level\",\"thread\": \"%thread\",\"logger\": \"%logger&#123;50&#125; %M %L \",\"message\": \"%msg\"&#125;&lt;/pattern&gt;&lt;/pattern&gt;&lt;/providers&gt;&lt;/encoder&gt;&lt;/appender&gt;&lt;root level=\"INFO\"&gt;&lt;appender-ref ref=\"LOGSTASH\"/&gt;&lt;/root&gt; yml添加配置12logstash: address: 192.168.1.169:4560 Kibana简介Kibana 是一个基于浏览器页面的Elasticsearch前端展示工具，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。 安装与配置 解压kibana-7.4.2-linux-x86_64.tar.gz，并修改配置文件kibana.yml 执行命令 1# ./kibana --allow-root 配置日期格式 create index pattern 保存自定义筛选字段，供后续筛选","categories":[{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"}],"tags":[{"name":"ES","slug":"ES","permalink":"http://geekvic.top/tags/ES/"},{"name":"Logstash","slug":"Logstash","permalink":"http://geekvic.top/tags/Logstash/"},{"name":"Kibana","slug":"Kibana","permalink":"http://geekvic.top/tags/Kibana/"}]},{"title":"Apollo环境配置","slug":"Apollo环境配置","date":"2019-08-27T09:00:00.000Z","updated":"2020-05-22T06:12:48.236Z","comments":true,"path":"post/92932283.html","link":"","permalink":"http://geekvic.top/post/92932283.html","excerpt":"一、背景&nbsp; &nbsp; Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。 二、配置环境路径 操作系统 server.properties hosts windows C:\\opt\\settings\\server.properties C:\\Windows\\System32\\drivers\\etc\\hosts linux /opt/settings/server.properties /etc/hosts 三、具体配置3.1&nbsp;server.propertiesenv=DEV","text":"一、背景&nbsp; &nbsp; Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。 二、配置环境路径 操作系统 server.properties hosts windows C:\\opt\\settings\\server.properties C:\\Windows\\System32\\drivers\\etc\\hosts linux /opt/settings/server.properties /etc/hosts 三、具体配置3.1&nbsp;server.propertiesenv=DEV 目前，env持以下几个值（大小写不敏感）： &nbsp; ● DEV &nbsp; &nbsp; &nbsp; ○ Development environment &nbsp; ● FAT &nbsp; &nbsp; &nbsp; ○ Feature Acceptance Test environment &nbsp; ● UAT &nbsp; &nbsp; &nbsp; ○ User Acceptance Test environment &nbsp; ● PRO &nbsp; &nbsp; &nbsp; ○ Production environment 3.2 hosts192.168.1.153 dev.config.ynt.ai 192.168.1.163 fat.config.ynt.ai 192.168.1.173 uat.config.ynt.ai 192.168.1.172 pro.config.ynt.ai","categories":[{"name":"配置管理","slug":"配置管理","permalink":"http://geekvic.top/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"Apollo","slug":"Apollo","permalink":"http://geekvic.top/tags/Apollo/"}]},{"title":"FFmpeg的安装与使用","slug":"FFmpeg的安装与使用","date":"2019-04-23T12:05:00.000Z","updated":"2020-05-22T06:12:48.238Z","comments":true,"path":"post/9fe0423b.html","link":"","permalink":"http://geekvic.top/post/9fe0423b.html","excerpt":"一、概述FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。采用LGPL或GPL许可证。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多code都是从头开发的。 二、安装2.1 安装yasm12345# wget http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz# tar -zxvf yasm-1.3.0.tar.gz# cd yasm-1.3.0# ./configure# make &amp;amp;&amp;amp; make install 2.2 安装FFmpeg123456#yum -y install bzip2#tar jxvf ffmpeg-4.0.2.tar.bz2#cd ffmpeg-4.0.2# ./configure# make# make install","text":"一、概述FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。采用LGPL或GPL许可证。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多code都是从头开发的。 二、安装2.1 安装yasm12345# wget http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz# tar -zxvf yasm-1.3.0.tar.gz# cd yasm-1.3.0# ./configure# make &amp;amp;&amp;amp; make install 2.2 安装FFmpeg123456#yum -y install bzip2#tar jxvf ffmpeg-4.0.2.tar.bz2#cd ffmpeg-4.0.2# ./configure# make# make install 2.3 查看ffmpeg是否安装成功1# ffmpeg 输入ffmpeg打印了相关信息，表示安装成功 三、转换将MP3转换为16000的采样率、单通道的wav格式，命令如下： 1ffmpeg -i G:\\test.mp3 -acodec pcm_s16le -ac 1 -ar 16000 -f wav \"G:\\test.wav\"","categories":[{"name":"工具","slug":"工具","permalink":"http://geekvic.top/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"http://geekvic.top/tags/FFmpeg/"}]},{"title":"Dubbo版本升级","slug":"Dubbo版本升级","date":"2019-04-10T12:00:00.000Z","updated":"2020-05-22T06:12:48.237Z","comments":true,"path":"post/1d29e395.html","link":"","permalink":"http://geekvic.top/post/1d29e395.html","excerpt":"一、背景早期内部使用的是当当网fork的Dubbox，由于现在Dubbo又开始重新维护，而且阿里将其捐献给了Apache，并成为了Apache的顶级项目。因此dubbo版本升级到2.7.1势在必行。 二、版本升级从2.8.4升级到2.7.1 具体可以参考： Dubbo Spring Boot (v2.7.1) :&nbsp;https://github.com/apache/incubator-dubbo-spring-boot-projectDubbo (v2.7.1) :&nbsp;https://github.com/apache/incubator-dubbo 三、遇到的问题","text":"一、背景早期内部使用的是当当网fork的Dubbox，由于现在Dubbo又开始重新维护，而且阿里将其捐献给了Apache，并成为了Apache的顶级项目。因此dubbo版本升级到2.7.1势在必行。 二、版本升级从2.8.4升级到2.7.1 具体可以参考： Dubbo Spring Boot (v2.7.1) :&nbsp;https://github.com/apache/incubator-dubbo-spring-boot-projectDubbo (v2.7.1) :&nbsp;https://github.com/apache/incubator-dubbo 三、遇到的问题 问题 解决思路 dubbo-admin启动成功，但是元数据和服务测试功能无法正常使用 zk服务端的版本问题。测试后发现当前只支持zk3.4.13版本，3.4.14或者3.5.5都不支持； admin的global配置问题，不能填写127.0.0.1，必须填写ip地址； zk节点可以通过zooInspector手动删除； dubbo服务启动多次后产生多个服务 2.7.1版本里zk的节点是默认静态节点，导致服务shutdown后依旧存在；此问题在2.7.2以后已经解决； 解决思路：优雅的关闭程序（1.idea中点击退出按钮，2.服务器上不要强杀进程，正常stop或者kill 进程） dubbo-admin启动后服务端显示127.0.0.1 主要是主机名默认是127.0.0.1 解决思路（1.修改主机名 hostnamectl&nbsp;set-hostname&nbsp;xxx.xxx.xxx.xxx 2.在配置文件里指定dubbo的host（不建议）） 序列化报错 建议使用kryo序列化，其序列化效率明显优于Java序列化，若使用Java序列化，则bean需要实现Serializable接口；kryo并不需要，直接引入jar包maven引用即可","categories":[{"name":"微服务","slug":"微服务","permalink":"http://geekvic.top/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://geekvic.top/tags/Dubbo/"}]},{"title":"Docker中安装mysql","slug":"Docker中安装mysql","date":"2018-12-15T12:37:00.000Z","updated":"2020-05-22T06:12:48.237Z","comments":true,"path":"post/6774ee31.html","link":"","permalink":"http://geekvic.top/post/6774ee31.html","excerpt":"1.docker 中下载 mysql docker pull mysql 2.启动 docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 3.进入容器 docker exec -it mysql bash 4.登录mysql，密码输入123456","text":"1.docker 中下载 mysql docker pull mysql 2.启动 docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 3.进入容器 docker exec -it mysql bash 4.登录mysql，密码输入123456 mysql -u root -p 5.添加远程登录用户 ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456'; FLUSH PRIVILEGES;","categories":[{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"}],"tags":[{"name":"Apollo","slug":"Apollo","permalink":"http://geekvic.top/tags/Apollo/"},{"name":"Mysql","slug":"Mysql","permalink":"http://geekvic.top/tags/Mysql/"},{"name":"Docker","slug":"Docker","permalink":"http://geekvic.top/tags/Docker/"}]},{"title":"Docker初识","slug":"Docker初识","date":"2018-12-13T13:54:00.000Z","updated":"2020-05-22T06:12:48.237Z","comments":true,"path":"post/8e06a8f9.html","link":"","permalink":"http://geekvic.top/post/8e06a8f9.html","excerpt":"一、简介&nbsp; &nbsp; Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 二、Docker与虚拟机的比较&nbsp; &nbsp; Docker是在操作系统进程层面的隔离，而虚拟机是在物理资源层面的隔离，两者完全不同，另外，我们也可以通过下面的一个比较，了解两者的根本性差异。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般为几十个","text":"一、简介&nbsp; &nbsp; Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 二、Docker与虚拟机的比较&nbsp; &nbsp; Docker是在操作系统进程层面的隔离，而虚拟机是在物理资源层面的隔离，两者完全不同，另外，我们也可以通过下面的一个比较，了解两者的根本性差异。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般为几十个 &nbsp; &nbsp; 从上面的容器与虚拟机的对比中，我们明白了容器技术的优势。 &nbsp; &nbsp; 容器就是一个不错的解决方案，容器能成为开发与运维之间沟通的语言，因为容器就像一个集装箱一样，提供了软件运行的最小化环境，将应用与其需要的环境一起打包成为镜像，便可以在开发与运维之间沟通与传输。我们常常会听到开发人员对运维人员说的这样一句话：&ldquo;在我的电脑运行没问题，怎么到了你那里就出问题了，肯定是你的问题&rdquo;，而运维人员则认为是开发人员的问题。通过Docker容器可以解决开发人员与运维人员之间的矛盾。 三、核心概念&nbsp; &nbsp; Docker 包括三个基本概念如下。具体关系如下图所示。 3.1 镜像（Image）&nbsp; &nbsp; Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。&nbsp; &nbsp; 3.2 容器（Container）&nbsp; &nbsp; 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 3.3 仓库（Repository）&nbsp; &nbsp; 仓库可看着一个代码控制中心，用来保存镜像。 四、Docker的版本&nbsp; &nbsp; Docker分为社区版(CE)和企业版(EE)两个版本，社区版本可以免费使用，而企业版则需要付费使用，对于我们个人开发者或小企业来说，一般是使用社区版的。 &nbsp; &nbsp; Docker CE有三个更新频道，分别为stable、test、nightly，stable是稳定版本，test是测试后的预发布版本，而nightly则是开发中准备在下一个版本正式发布的版本，我们可以根据自己的需求下载安装。 五、如何安装5.1 安装必要的一些系统工具 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 5.2 添加软件源信息 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 5.3 更新并安装Docker-CE sudo yum makecache fast sudo yum -y install docker-ce 5.4 开启Docker服务 sudo service docker start 5.5 查看docker版本 docker version 5.6 开启 docker 并设置开机自启动 systemctl start docker symctl enable d","categories":[{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://geekvic.top/tags/Docker/"}]},{"title":"Java项目main方法启动的两种方式","slug":"Java项目main方法启动的两种方式","date":"2018-11-26T08:36:00.000Z","updated":"2020-05-22T06:12:48.240Z","comments":true,"path":"post/60af2b16.html","link":"","permalink":"http://geekvic.top/post/60af2b16.html","excerpt":"","text":"1.打包时指定了主类，可以直接用java -jar xxx.jar123456789101112131415161718192021222324&lt;!--main方法打包jar包插件--&gt;&lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.TestApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;assembly&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 2.打包时没有指定主类，可以用java -cp xxx.jar 主类名称（绝对路径）1java -cp xxx.jar com.TestApplication","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://geekvic.top/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://geekvic.top/tags/Java/"}]},{"title":"zookeeper安装","slug":"Zookeeper安装","date":"2018-11-20T13:00:00.000Z","updated":"2020-05-22T06:12:48.246Z","comments":true,"path":"post/bf5e4a43.html","link":"","permalink":"http://geekvic.top/post/bf5e4a43.html","excerpt":"1.下载zk软件http://www.apache.org/dyn/closer.cgi/zookeeper/ 2.解压压缩包1# tar zxvf zookeeper-3.4.13.tar.gz 3.创建zoo.cfg12# cd zookeeper-3.4.13/conf# cp zoo_sample.cfg zoo.cfg 4.获取zk的路径","text":"1.下载zk软件http://www.apache.org/dyn/closer.cgi/zookeeper/ 2.解压压缩包1# tar zxvf zookeeper-3.4.13.tar.gz 3.创建zoo.cfg12# cd zookeeper-3.4.13/conf# cp zoo_sample.cfg zoo.cfg 4.获取zk的路径1# pwd /home/software/zookeeper-3.4.13 5.修改zoo.cfg1# vim zoo.cfg 设置dataDir=/home/software/zookeeper-3.4.13/data 6.zk启动、关闭、查看状态1# cd bin 启动 1# ./zkServer.sh start 关闭 1# ./zkServer.sh stop 查看状态 1# ./zkServer.sh status","categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://geekvic.top/categories/zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://geekvic.top/tags/zookeeper/"}]},{"title":"内网穿透反向代理工具frp的使用","slug":"内网穿透反向代理工具frp的使用","date":"2018-03-10T13:03:00.000Z","updated":"2020-05-22T06:12:48.249Z","comments":true,"path":"post/310667e0.html","link":"","permalink":"http://geekvic.top/post/310667e0.html","excerpt":"1.背景frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。场景：近期在研究微信公众号开发，发现需要暴露公网地址，并且是80端口的服务，正好手边有朋友买了腾讯云服务器，因此想通过腾讯云服务器作为frp的服务端，本地机器作为客户端，让公网可以直接访问内网本地机器发布的服务，实现内网穿透。 2.作用 利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。 对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。 利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 3.具体实现通过tcp方式访问公司内网服务（当前公网服务器没有绑定域名的情况下） 1234567891011121314151617181920#修改 frps.ini 文件，这里使用了最简化的配置：# frps.ini[common]bind_port = 7000启动 frps：./frps -c ./frps.ini#修改 frpc.ini 文件，假设 frps 所在服务器的公网 IP 为 x.x.x.x；# frpc.ini[common]server_addr = x.x.x.xserver_port = 7000[ssh]type = tcplocal_ip = 127.0.0.1local_port = 8088remote_port = 80启动 frpc：./frpc -c ./frpc.ini","text":"1.背景frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。场景：近期在研究微信公众号开发，发现需要暴露公网地址，并且是80端口的服务，正好手边有朋友买了腾讯云服务器，因此想通过腾讯云服务器作为frp的服务端，本地机器作为客户端，让公网可以直接访问内网本地机器发布的服务，实现内网穿透。 2.作用 利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。 对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。 利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 3.具体实现通过tcp方式访问公司内网服务（当前公网服务器没有绑定域名的情况下） 1234567891011121314151617181920#修改 frps.ini 文件，这里使用了最简化的配置：# frps.ini[common]bind_port = 7000启动 frps：./frps -c ./frps.ini#修改 frpc.ini 文件，假设 frps 所在服务器的公网 IP 为 x.x.x.x；# frpc.ini[common]server_addr = x.x.x.xserver_port = 7000[ssh]type = tcplocal_ip = 127.0.0.1local_port = 8088remote_port = 80启动 frpc：./frpc -c ./frpc.ini 通过http的方式访问公司内网服务（当前公网服务器已经绑定域名的情况下） 12345678910111213141516171819202122#修改 frps.ini 文件[common]# frp服务监听client的端口bind_port = 7000# http形式的外网开放端口vhost_http_port = 7001# 子域名subdomain_host = vic.com#修改 frpc.ini 文件[http-8088]# http-8051 表示名字，随便起# type有http、tcp等多种类型，一般只用这两种type = http# 需要穿透内网服务的iplocal_ip = 192.168.1.187# 内网服务的端口local_port = 8088# 子域名，因为ynt.ai开启了域名泛解析，二级域名只是作为每个服务的区分# 不可与其他服务的子域名重复subdomain = test# 比如这个服务只用访问 http://test.vic.com:7001就可以访问到 通过浏览器查看 frp 的状态以及代理统计信息展示。需要在 frps.ini 中指定 dashboard 服务使用的端口，即可开启此功能： 12345[common]dashboard_port = 7500# dashboard 用户名密码，默认都为 admindashboard_user = admindashboard_pwd = admin 打开浏览器通过&nbsp;http://[server_addr]:7500&nbsp;访问 dashboard 界面，用户名密码默认为&nbsp;admin。","categories":[{"name":"工具","slug":"工具","permalink":"http://geekvic.top/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"frp","slug":"frp","permalink":"http://geekvic.top/tags/frp/"}]},{"title":"Nginx负载均衡初识","slug":"Nginx负载均衡初识","date":"2018-02-22T09:33:00.000Z","updated":"2020-05-22T06:12:48.241Z","comments":true,"path":"post/c75d9605.html","link":"","permalink":"http://geekvic.top/post/c75d9605.html","excerpt":"1.背景 nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；nginx可以作为一个HTTP服务器进行网站的发布处理，另外nginx可以作为反向代理进行负载均衡的实现。 2.安装 下载nginx最新版本到linux服务器上，解压tar -zxvf nginx-1.13.8.tar.gz，进入解压目录 cd nginx-1.13.8，并进行手动安装。 配置： 1./configure --prefix=/usr/local/nginx 编辑nginx： 1make","text":"1.背景 nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；nginx可以作为一个HTTP服务器进行网站的发布处理，另外nginx可以作为反向代理进行负载均衡的实现。 2.安装 下载nginx最新版本到linux服务器上，解压tar -zxvf nginx-1.13.8.tar.gz，进入解压目录 cd nginx-1.13.8，并进行手动安装。 配置： 1./configure --prefix=/usr/local/nginx 编辑nginx： 1make 安装： 1make install 启动nginx： 1sudo /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 3.修改配置 在/usr/local/nginx/conf#目录下执行vim nginx.conf，进行nginx的配置，采用轮询的方式，端口号：8066，如下： 1234567891011121314151617181920212223#gzip on; upstream test&#123; server 192.168.1.15:8087 weight=10; server 192.168.1.15:8088 weight=10; &#125; server &#123; listen 8066; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://test; root html; index index.html index.htm; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; 4.启动nginx1./sbin/nginx 5.停止nginx1./sbin/nginx -s stop 6.访问服务通过http://localhost:8066负载均衡访问192.168.1.15上的两个服务。 7.负载均衡 nginx支持的负载均衡调度算法方式如下： weight轮询（默认）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。 ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。 fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块 url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://geekvic.top/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://geekvic.top/tags/Nginx/"}]},{"title":"GitLab问题小结","slug":"GitLab问题小结","date":"2018-01-06T11:00:00.000Z","updated":"2020-05-22T06:12:48.239Z","comments":true,"path":"post/c47a15e1.html","link":"","permalink":"http://geekvic.top/post/c47a15e1.html","excerpt":"","text":"1.内存消耗太大 （1）公司使用gitlab后，发现服务器内存居高不下，使用top命令查看内存消耗，发现服务器上git将近消耗一半内存资源。而且很奇怪的是竟然开启了32个进程。后经查资料，原来这跟gitlab的默认机制有关。在配置文件/etc/gitlab/gitlab.rb里，unicorn[‘worker_processes’] = 2，默认是被注释掉的，这就解释了为什么会开启32个进程，因为cpu有32核，如果服务器只用于GitLab的话，官方建议是CPU核心数加一，可以提高服务器的响应速度。不过如果内存只有4G，或者服务器同时承载其他服务，就不要改了，以免内存不足。另外，这个参数最小值是2，设为1，服务器可能会卡死。 （2）解决方案：根据服务器使用情况，给unicorn[‘worker_processes’]设置一个合适的值，可解决内存占用过大问题。 2.时间不一致 gitlab的web页面上activity里显示的时间相差8小时，很有可能是时区设置问题，设置时区为：gitlab_rails[‘time_zone’] = ‘Asia/Shanghai’，还有种可能是服务器本身的时间有问题，服务器服务时间修改注意事项：写入clock -w &nbsp;,强制将时间写入COMS！这样重启后不会失效。&nbsp;","categories":[{"name":"Git","slug":"Git","permalink":"http://geekvic.top/categories/Git/"}],"tags":[{"name":"GitLab","slug":"GitLab","permalink":"http://geekvic.top/tags/GitLab/"}]},{"title":"GitLab服务器迁移","slug":"GitLab服务器迁移","date":"2018-01-06T01:58:00.000Z","updated":"2020-05-22T06:12:48.238Z","comments":true,"path":"post/6b0e3bbc.html","link":"","permalink":"http://geekvic.top/post/6b0e3bbc.html","excerpt":"一、背景由于GitLab内存消耗很大，已经影响到A服务器上的其他服务，同时考虑到代码管理服务应该单独部署在一台服务器上，因此决定从服务器A迁移到服务器B上。两台服务器均是CentOS 7，gitlab版本是gitlab-ce-9.5.6-ce.0.el7.x86_64.rpm 。注意：高版本的Gitlab无法恢复低版本备份的数据,需要注意在B服务器部署和A服务器一样版本的gitlab,部署好环境后开始备份和数据迁移。 二、备份备份A服务器上的gitlab数据，执行命令： 1gitlab-rake gitlab:backup:create RAILS_ENV=production PS: 备份后的文件一般是位于/var/opt/gitlab/backups下。 三、拷贝","text":"一、背景由于GitLab内存消耗很大，已经影响到A服务器上的其他服务，同时考虑到代码管理服务应该单独部署在一台服务器上，因此决定从服务器A迁移到服务器B上。两台服务器均是CentOS 7，gitlab版本是gitlab-ce-9.5.6-ce.0.el7.x86_64.rpm 。注意：高版本的Gitlab无法恢复低版本备份的数据,需要注意在B服务器部署和A服务器一样版本的gitlab,部署好环境后开始备份和数据迁移。 二、备份备份A服务器上的gitlab数据，执行命令： 1gitlab-rake gitlab:backup:create RAILS_ENV=production PS: 备份后的文件一般是位于/var/opt/gitlab/backups下。 三、拷贝从A服务上拷贝gitlab数据到B服务器上，执行命令： 1scp root@A_ip:/var/opt/gitlab/backups/1515132280_2018_01_05_9.5.6_gitlab_backup.tar /var/opt/gitlab/backups 其中A_ip是A服务器IP地址。 四、还原在B服务器的/var/opt/gitlab/backups的目录下还原gitlab数据，执行命令： 1gitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=1515132280_2018_01_05_9.5.6 PS：BACKUP的参数必须与原服务器备份后的文件名一致。 五、问题还原过程中报错，报错：无法 open:权限不够，估计是拷贝过来的还原文件权限不够，执行命令： 1chmod 644 1515132280_2018_01_05_9.5.6_gitlab_backup.tar 再次执行还原命令即可成功。","categories":[{"name":"Git","slug":"Git","permalink":"http://geekvic.top/categories/Git/"}],"tags":[{"name":"GitLab","slug":"GitLab","permalink":"http://geekvic.top/tags/GitLab/"}]},{"title":"idea使用Protobuf插件","slug":"idea使用Protobuf插件","date":"2017-11-06T09:06:00.000Z","updated":"2020-05-22T06:12:48.247Z","comments":true,"path":"post/35fe24ef.html","link":"","permalink":"http://geekvic.top/post/35fe24ef.html","excerpt":"1.protobuf简介 Protobuf是一个灵活的、高效的用于序列化数据的协议。相比较XML和JSON格式，protobuf更小、更快、更便捷。Protobuf是跨语言的，并且自带了一个编译器(protoc)，只需要用它进行编译，可以编译成Java、python、C++等代码，然后就可以直接使用，不需要再写其他代码，自带有解析的代码。一条消息数据，用protobuf序列化后的大小是json的10分之一，xml格式的20分之一，是二进制序列化的10分之一。 2.安装插件在idea里安装插件Protobuf Support 3.配置1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;$&#123;protobuf.version&#125;&lt;/version&gt;&lt;/dependency&gt; 1234567&lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt;&lt;/extensions&gt;","text":"1.protobuf简介 Protobuf是一个灵活的、高效的用于序列化数据的协议。相比较XML和JSON格式，protobuf更小、更快、更便捷。Protobuf是跨语言的，并且自带了一个编译器(protoc)，只需要用它进行编译，可以编译成Java、python、C++等代码，然后就可以直接使用，不需要再写其他代码，自带有解析的代码。一条消息数据，用protobuf序列化后的大小是json的10分之一，xml格式的20分之一，是二进制序列化的10分之一。 2.安装插件在idea里安装插件Protobuf Support 3.配置1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;$&#123;protobuf.version&#125;&lt;/version&gt;&lt;/dependency&gt; 1234567&lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt;&lt;/extensions&gt; 123456789101112131415161718192021222324&lt;!--protobuf插件--&gt;&lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt; com.google.protobuf:protoc:$&#123;protobuf.version&#125;:exe:$&#123;os.detected.classifier&#125; &lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt; io.grpc:protoc-gen-grpc-java:$&#123;grpc.version&#125;:exe:$&#123;os.detected.classifier&#125; &lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 4.创建proto文件123456789syntax = \"proto3\";option java_package = \"com.ynt.ai.activemq.protobuf\";option java_outer_classname = \"PersonModel\";message Person &#123; int32 id = 1; string name = 2; string email = 3;&#125; 5.生成java对象文件 通过Protobuf插件的compile命令，如下图所示，自动生成对象文件。 6.测试123456PersonMsg.Person person = PersonMsg.Person.newBuilder().setId(2).setName(\"test\") .setEmail(\"test@163.com\").build(); byte[] results = person.toByteArray(); for (byte b : results) &#123; log.info(String.valueOf(b)); &#125;","categories":[{"name":"通信协议","slug":"通信协议","permalink":"http://geekvic.top/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"Protobuf","slug":"Protobuf","permalink":"http://geekvic.top/tags/Protobuf/"}]},{"title":"Linux环境GitLab安装与配置","slug":"Linux环境GitLab安装与配置","date":"2017-10-30T09:22:00.000Z","updated":"2020-05-22T06:12:48.240Z","comments":true,"path":"post/4fe954de.html","link":"","permalink":"http://geekvic.top/post/4fe954de.html","excerpt":"1.背景 近期公司源代码管理工具从svn转向git，因此要在服务器上部署gitlab，总共部署了两台服务器，一台是Ubuntu server 17.04，一台是Centos7。在部署的过程中遇到不少问题，发现Linux里通过命令直接去Gitlab官网上下载程序根本不能成功，不管是在Ubuntu还是Centos上。后来只能去Gitlab官网手动下载安装包，然后再去Linux里通过命令去执行才能安装。 2.软件下载2.1 Gitlab官网 官网地址：https://about.gitlab.com/downloads/ 2.2 镜像站 软件地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/xenial/main/g/gitlab-ce/但是有时候镜像站也会打不开，但是速度肯定要比官网快多了。","text":"1.背景 近期公司源代码管理工具从svn转向git，因此要在服务器上部署gitlab，总共部署了两台服务器，一台是Ubuntu server 17.04，一台是Centos7。在部署的过程中遇到不少问题，发现Linux里通过命令直接去Gitlab官网上下载程序根本不能成功，不管是在Ubuntu还是Centos上。后来只能去Gitlab官网手动下载安装包，然后再去Linux里通过命令去执行才能安装。 2.软件下载2.1 Gitlab官网 官网地址：https://about.gitlab.com/downloads/ 2.2 镜像站 软件地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/xenial/main/g/gitlab-ce/但是有时候镜像站也会打不开，但是速度肯定要比官网快多了。 2.3 Ubuntu版本Ubuntu server 17.04下载的版本是gitlab-ce_9.5.6-ce.0_amd64.deb 2.4 Centos版本centos7下载的版本是gitlab-ce-9.5.6-ce.0.el7.x86_64.rpm 3.安装3.1 ubuntu环境 执行命令： 1$ apt-get install curl openssh-server ca-certificates postfix 配置postfix邮箱 使用命令： 1$ dpkg -i gitlab-ce_9.5.6-ce.0_amd64.deb 出现 It looks like&hellip; 表示安装成功！ 配置gitlab 1234mkdir -p /etc/gitlabtouch /etc/gitlab/gitlab.rbchmod 600 /etc/gitlab/gitlab.rbvim/etc/gitlab/gitlab.rb 把external_url改成部署机器的域名或者IP地址 执行命令： 12gitlab-ctl reconfiguregitlab-ctl status 安装完成。 3.2 centos环境 配置postfix邮箱： 1yum -y install policycoreutils openssh-server openssh-clients postfix 安装gitlab： 1$ rpm -i gitlab-ce-9.5.6-ce.0.el7.x86_64.rpm 修改gitlab配置文件指定服务器ip和自定义端口，修改external_url，命令： 1vim /etc/gitlab/gitlab.rb 执行命令： 1gitlab-ctl reconfigure、gitlab-ctl restart 安装完成 4.提醒 邮箱自动提醒功能有问题 gitlab会占用8080端口，建议服务器上的tomcat修改下端口号，否则会有问题。 访问主机ip就可以访问gitlab主页了。","categories":[{"name":"Git","slug":"Git","permalink":"http://geekvic.top/categories/Git/"}],"tags":[{"name":"GitLab","slug":"GitLab","permalink":"http://geekvic.top/tags/GitLab/"}]},{"title":"ubuntu安装redis","slug":"ubuntu安装redis","date":"2017-10-30T08:36:00.000Z","updated":"2020-05-22T06:12:48.248Z","comments":true,"path":"post/ad24f30b.html","link":"","permalink":"http://geekvic.top/post/ad24f30b.html","excerpt":"1.背景服务器：ubuntu server 17.04 安装方式：apt-get 2.实现 执行命令： 1$ apt-get update 执行命令：","text":"1.背景服务器：ubuntu server 17.04 安装方式：apt-get 2.实现 执行命令： 1$ apt-get update 执行命令： 1$ apt-get install redis-server 启用redis： 1$ redis-server 查看redis是否启用： 1$ redis-cli redis 127.0.0.1:6379&gt;ping，返回PONG，说明redis已经安装成功。 redis默认是只允许本地访问，如果要让其远程访问，还需要修改配置。执行$ vim /etc/redis/redis.conf，注释bind 127.0.0.1，除此之外，还需要关闭保护模式，protected-mode默认是yes，需要将protected-mode设置为 no 再重启下redis： 1$ redis-server 3.远程访问本机环境：win10，安装redis客户端RedisDesktopManager，通过设置ip地址，redis端口号等，可以远程连接ubuntu上安装的redis，如下图所示。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/categories/Linux/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://geekvic.top/tags/ubuntu/"},{"name":"redis","slug":"redis","permalink":"http://geekvic.top/tags/redis/"}]},{"title":"ubuntu修改apt-get源","slug":"ubuntu修改apt-get源","date":"2017-10-30T08:11:00.000Z","updated":"2020-05-22T06:12:48.248Z","comments":true,"path":"post/ca00f598.html","link":"","permalink":"http://geekvic.top/post/ca00f598.html","excerpt":"1.背景 服务器上安装了最新的Ubuntu Server 17.04，代号为zesty。使用apt-get命令安装软件时，有时候速度比较慢，有时候会失败。因此考虑用国内的镜像源更换下apt-get的默认源。 2.实现 编辑源文件，vim /etc/apt/sources.list 使用网易apt-get源，将原来的源地址，替换为如下，由于服务器的版本是17.04，因此源地址的代号部分都是zesty，如果是其他版本，可以替换为对应的版本，具体版本代号可以网上查找。 12345678910deb http://mirrors.163.com/ubuntu/ zesty main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiverse 执行apt-get update，apt-get upgrade，会发现会报错，apt-get: Could not resolve ‘mirrors.163.com&rsquo;的错误，这种原因其实是因为还缺少一个步骤，就是将添加的网址和IP进行映射，修改/etc/目录下的host文件。 通过ip.chinaz.com进行查询网址&ldquo;mirrors.163.com&rdquo;，对应的ip地址如下所示，然后将其添加到hosts文件里。 12123.58.190.228 mirrors.163.com123.58.190.236 mirrors.163.com","text":"1.背景 服务器上安装了最新的Ubuntu Server 17.04，代号为zesty。使用apt-get命令安装软件时，有时候速度比较慢，有时候会失败。因此考虑用国内的镜像源更换下apt-get的默认源。 2.实现 编辑源文件，vim /etc/apt/sources.list 使用网易apt-get源，将原来的源地址，替换为如下，由于服务器的版本是17.04，因此源地址的代号部分都是zesty，如果是其他版本，可以替换为对应的版本，具体版本代号可以网上查找。 12345678910deb http://mirrors.163.com/ubuntu/ zesty main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ zesty-backports main restricted universe multiverse 执行apt-get update，apt-get upgrade，会发现会报错，apt-get: Could not resolve ‘mirrors.163.com&rsquo;的错误，这种原因其实是因为还缺少一个步骤，就是将添加的网址和IP进行映射，修改/etc/目录下的host文件。 通过ip.chinaz.com进行查询网址&ldquo;mirrors.163.com&rdquo;，对应的ip地址如下所示，然后将其添加到hosts文件里。 12123.58.190.228 mirrors.163.com123.58.190.236 mirrors.163.com 再执行apt-get update，apt-get upgrade，就配置好了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/categories/Linux/"}],"tags":[{"name":"apt-get","slug":"apt-get","permalink":"http://geekvic.top/tags/apt-get/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://geekvic.top/tags/ubuntu/"}]},{"title":"Linux的常用命令","slug":"Linux的常用命令","date":"2017-10-27T10:00:00.000Z","updated":"2020-05-22T06:12:48.240Z","comments":true,"path":"post/4ad0b8cc.html","link":"","permalink":"http://geekvic.top/post/4ad0b8cc.html","excerpt":"1.常用指令（1）切换用户： su 用户名 （2）默认切换到root用户： su （3）回到根目录：cd / （4）进入某个目录：cd /usr/ （5）回到上级目录：cd .. （6）自动补齐目录文件名 Tab键","text":"1.常用指令（1）切换用户： su 用户名 （2）默认切换到root用户： su （3）回到根目录：cd / （4）进入某个目录：cd /usr/ （5）回到上级目录：cd .. （6）自动补齐目录文件名 Tab键 （7）查看某个程序的进程号： ps -ef | grep tomcat （8）根据进程查看端口号：netstat -naop | grep 2020 （9）根据端口号查看进程：lsof -i:8088 （10）显示文件或目录： ls （11）列出文件或目录详细信息： ll （12）创建目录： mkdir （13）创建空文件：touch （14）查看文件内容：cat （15）拷贝：cp （16）移动或重命名：mv （17）删除：rm （18）递归删除：rm -r &nbsp; （19）强制删除：rm -f （20）在文件里搜索：find&nbsp; （21）统计文本中行数、字数、字符数：wc （22）在文本文件中查找某个字符串：grep （23）显示当前目录：pwd （24）从windows拷贝文件到Linux：rz （25）查看所有运行的程序 ps -ef （26）编辑文件 vim （27）用于字符串的输出 echo $CLASSPATH （28）pwdx pid用来查看正在运行的线程所在的目录 （29）pwd 查看当前目录 （30）ldconfig&nbsp;搜寻目录/lib和/usr/lib以及动态库配置文件/etc/ld.so.conf内所列的目录下的共享动态链接库 （31）从Linux拷贝文件到windows：sz （32）查看防火墙开启状态&nbsp;firewall-cmd –state （33）查看文件的MD5值 md5sum （34）查找文件&nbsp;find / -name 文件名 （35）返回到上次的目录，类似windows返回 &nbsp;cd - （36）回到用户主目录 cd ~ 或者cd &nbsp; (37) 查看服务器存储情况&nbsp; df -h （38）查看cpu信息&nbsp; cat /proc/cpuinfo （39）查看内存信息 cat /proc/meminfo （40）查看剩余内存&nbsp; free &nbsp; (41)&nbsp; 查看上一次重启、关机记录 last | grep reboot，last | grep shutdown （42）查看历史操作记录&nbsp; history 、history 10 （43）查找文件&nbsp; find / -name test.txt &nbsp; (44)&nbsp; 查找文件通配符&nbsp; find /project -name ‘test.txt‘ 2.系统管理命令（1）显示指定文件的详细信息，比ls更详细：stat /etc （2）显示在线登陆用户：who （3）显示当前操作用户：whoami （4）显示主机名：hostname （5）显示系统信息：uname （6）动态显示当前耗费资源最多进程信息：top （7）显示瞬间进程状态 ：ps -aux （8）查看磁盘大小：df （9）查看网络情况： ifconfig （10）测试网络连通：ping （11）&nbsp;显示网络状态信息：netstatus （12）清屏：clear （13）杀死进程：kill&nbsp; （14）强杀进程：kill -9 （15）终止程序 ：Ctrl+C （16）挂起程序 ：Ctrl+V （17）查看某个进程的内存情况：top -p pid 3.关机重启系统（1）关机重启：shutdown -r （2）关机不重启： shutdown -h （3）立刻关机： shutdown now （4）关机： halt （5）重启： reboot 4.Vim工具（1）退出：q （2）强制退出：q! （3）保存并退出：wq （4）切换命令模式与插入模式：ESC，i，o （5）删除一行：dd （6）到文件开头： gg （7）到文件结尾： shift+g 5.压缩工具（1）tar.gz 和 .tgz &nbsp; &nbsp; 解压：tar zxvf FileName.tar.gz &nbsp; &nbsp; 压缩：tar zcvf FileName.tar.gz DirName （2）zip &nbsp;解压：unzip FileName.zip &nbsp;压缩：zip FileName.zip DirName （3）rar &nbsp;解压：rar x FileName.rar &nbsp;压缩：rar a FileName.rar DirName （4）tar&nbsp;解包：tar xvf FileName.tar &nbsp;打包：tar cvf FileName.tar DirName （5）gz &nbsp;解压：gzip -d FileName.gz &nbsp;压缩：gzip FileName &nbsp;","categories":[{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/tags/Linux/"}]},{"title":"ubuntu允许root远程登录配置","slug":"ubuntu允许root远程登录配置","date":"2017-10-19T13:02:00.000Z","updated":"2020-05-22T06:12:48.248Z","comments":true,"path":"post/bbcdf51b.html","link":"","permalink":"http://geekvic.top/post/bbcdf51b.html","excerpt":"1.背景近期在本地的虚拟机VMware上安装了Ubuntu Server 17.04，由于系统是无界面的，所有操作都需要通过Linux命令进行操作。后来不想直接在服务器上操作，想通过远程工具Xshell去访问Linux系统。却发现根本连接不上。后来查资料，原来需要在Ubuntu上安装SSH协议软件，因为Ubuntu默认是不安装SSH服务的。安装了SSH服务后发现其他用户可以通过Xshell远程访问了，root用户访问会报密码被拒绝的错误，上网查资料，发现Ubuntu默认是不开启root远程登录的，需要设置一下。 2.实现2.1 检查是否开启SSH服务命令： 1ps -e|grep ssh 查看SSH服务是否开启，或者通过命令：","text":"1.背景近期在本地的虚拟机VMware上安装了Ubuntu Server 17.04，由于系统是无界面的，所有操作都需要通过Linux命令进行操作。后来不想直接在服务器上操作，想通过远程工具Xshell去访问Linux系统。却发现根本连接不上。后来查资料，原来需要在Ubuntu上安装SSH协议软件，因为Ubuntu默认是不安装SSH服务的。安装了SSH服务后发现其他用户可以通过Xshell远程访问了，root用户访问会报密码被拒绝的错误，上网查资料，发现Ubuntu默认是不开启root远程登录的，需要设置一下。 2.实现2.1 检查是否开启SSH服务命令： 1ps -e|grep ssh 查看SSH服务是否开启，或者通过命令： 1service sshd status 可以查看某个服务的状态。 2.2 安装SSH服务通过apt-get 安装，命令： 1apt-get install ssh; 2.3 启动SSH服务命令： 1sudo /etc/init.d/ssh start 2.4 修改SSH配置文件命令： 1sudo vim /etc/ssh/sshd_config 找到PermitRootLogin without-password 修改为PermitRootLogin yes 2.5 重启SSH服务命令： 1service ssh restart","categories":[{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/categories/Linux/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://geekvic.top/tags/ubuntu/"}]},{"title":"Spring Boot 热部署devtools实现","slug":"Spring Boot 热部署devtools实现","date":"2017-10-19T02:02:00.000Z","updated":"2020-05-22T06:12:48.241Z","comments":true,"path":"post/5945bf9f.html","link":"","permalink":"http://geekvic.top/post/5945bf9f.html","excerpt":"1.devtoolsspring为开发者提供了一个名为spring-boot-devtools的模块来使Spring Boot应用支持热部署，提高开发者的开发效率，无需手动重启Spring Boot应用。 2.项目搭建本文是采用IDEA搭建的Spring Boot应用，通过spring-boot-devtools配置，可以支持修改java文件会自动重启程序，一些资源无需触发重启，例如thymeleaf模板文件就可以实时编辑。默认情况下，更改/META-INF/maven，/META-INF/resources ，/resources ，/static ，/public 或/templates下的资源不会触发重启，而是触发livereload。devtools模块包含一个嵌入的livereload服务器，可以在资源变化时用来触发浏览器刷新。浏览器需要在livereload.com下载安装扩展。 例如Chrome浏览器在应用商店安装livereload插件后，在要自动刷新的页面点击对应的图标，启动应用后更新页面内容或者css等都会触发页面自动刷新。 3.livereloadlivereload 通过引入的脚本livereload.js在 livereload 服务和浏览器之间建立了一个 WebSocket 连接。每当监测到文件的变动，livereload 服务就会向浏览器发送一个信号，浏览器收到信号后就刷新页面，实现了实时刷新的效果。每次启动时，需要点击对应的图标，如下图所示。","text":"1.devtoolsspring为开发者提供了一个名为spring-boot-devtools的模块来使Spring Boot应用支持热部署，提高开发者的开发效率，无需手动重启Spring Boot应用。 2.项目搭建本文是采用IDEA搭建的Spring Boot应用，通过spring-boot-devtools配置，可以支持修改java文件会自动重启程序，一些资源无需触发重启，例如thymeleaf模板文件就可以实时编辑。默认情况下，更改/META-INF/maven，/META-INF/resources ，/resources ，/static ，/public 或/templates下的资源不会触发重启，而是触发livereload。devtools模块包含一个嵌入的livereload服务器，可以在资源变化时用来触发浏览器刷新。浏览器需要在livereload.com下载安装扩展。 例如Chrome浏览器在应用商店安装livereload插件后，在要自动刷新的页面点击对应的图标，启动应用后更新页面内容或者css等都会触发页面自动刷新。 3.livereloadlivereload 通过引入的脚本livereload.js在 livereload 服务和浏览器之间建立了一个 WebSocket 连接。每当监测到文件的变动，livereload 服务就会向浏览器发送一个信号，浏览器收到信号后就刷新页面，实现了实时刷新的效果。每次启动时，需要点击对应的图标，如下图所示。 4.项目代码配置4.1 pom.xml配置文件123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;!-- 如果没有该配置，devtools不会生效 --&gt; &lt;/configuration&gt;&lt;/plugin&gt; 4.2 yml配置123456devtools: livereload: enabled: true #是否支持livereload port: 35729 restart: enabled: true #是否支持热部署 5.IDEA配置 File-Settings-Compiler-Build project automatically ctrl + shift + alt + /,选择Registry,勾上 Compiler autoMake allow when app running 6.安装livereload插件下载livereload插件，将其安装到chrome扩展程序中，并选中允许访问文件网址。 7.测试 修改类 应用会重启 修改配置文件 应用会重启 修改静态文件（html、css等），应用不会重启，但是会调用livereload，浏览器会自动刷新，显示最新的修改内容。","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/tags/Spring-Boot/"}]},{"title":"基于JMS的ActiveMQ搭建与实现","slug":"基于JMS的ActiveMQ搭建与实现","date":"2017-08-28T02:21:00.000Z","updated":"2020-05-22T06:12:48.250Z","comments":true,"path":"post/ae440fc9.html","link":"","permalink":"http://geekvic.top/post/ae440fc9.html","excerpt":"1.JMS简介Java消息服务（Java Message Service）即JMS，是一个Java平台中关于面向消息中间件的API，用于两个程序之间，或分布式系统中发送消息，进行异步通信。JMS包括队列与主题两种模式，一种是点对点的Queue，还有一个是发布订阅的Topic方式。区别在于： 对于Queue模式，一个发布者发布消息，下面的接收者按队列顺序接收，比如发布了10个消息，两个接收者A,B那就是A,B总共会收到10条消息，不重复。 对于Topic模式，一个发布者发布消息，有两个接收者A,B来订阅，那么发布了10条消息，A,B各收到10条消息。 消息中间件 2.消息中间件的用途和优点 将数据从一个应用程序传送到另一个应用程序，或者从软件的一个模块传送到另外一个模块； 负责建立网络通信的通道，进行数据的可靠传送； 保证数据不重发，不丢失 ； 能够实现跨平台操作，能够为不同操作系统上的软件集成技工数据传送服务。 3.ActiveMQActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。","text":"1.JMS简介Java消息服务（Java Message Service）即JMS，是一个Java平台中关于面向消息中间件的API，用于两个程序之间，或分布式系统中发送消息，进行异步通信。JMS包括队列与主题两种模式，一种是点对点的Queue，还有一个是发布订阅的Topic方式。区别在于： 对于Queue模式，一个发布者发布消息，下面的接收者按队列顺序接收，比如发布了10个消息，两个接收者A,B那就是A,B总共会收到10条消息，不重复。 对于Topic模式，一个发布者发布消息，有两个接收者A,B来订阅，那么发布了10条消息，A,B各收到10条消息。 消息中间件 2.消息中间件的用途和优点 将数据从一个应用程序传送到另一个应用程序，或者从软件的一个模块传送到另外一个模块； 负责建立网络通信的通道，进行数据的可靠传送； 保证数据不重发，不丢失 ； 能够实现跨平台操作，能够为不同操作系统上的软件集成技工数据传送服务。 3.ActiveMQActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。 4.ActiveMQ安装 官方网址：http://activemq.apache.org/，下载对应的程序，如下图所示。 解压到本地，在apache-activemq-5.15.0\\bin\\win64的目录下选择InstallService.bat启动服务，这样下次只要到系统服务里去启动与关闭，如下图所示。 至此，activemq的服务已经启动。 5.Demo项目结构 6.代码实现生产者消费者模式6.1 配置依赖项在pom.xml里添加依赖jar包 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 6.2 实现生产者（队列模式）12345678910111213141516171819202122232425262728293031323334353637383940414243package com.snail.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * 生产者（队列模式） * Create by zhangviv * 2017-08-25 14:06 **/public class AppProducer &#123; private static final String url = \"tcp://localhost:61616\"; private static final String queueName = \"queue-test\"; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(url); //2.创建连接 Connection connection = connectionFactory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 Destination destination = session.createQueue(queueName); //6.创建一个生产者 MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage = session.createTextMessage(\"test\" + i); producer.send(textMessage); System.out.println(\"发送消息：\" + textMessage.getText()); &#125; //8.关闭连接 connection.close(); &#125;&#125; 6.3 实现消费者（队列模式）123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.snail.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * 消费者（队列模式） * Create by zhangviv * 2017-08-25 14:12 **/public class AppConsumer &#123; private static final String url=\"tcp://localhost:61616\"; private static final String queueName=\"queue-test\"; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory ConnectionFactory connectionFactory=new ActiveMQConnectionFactory(url); //2.创建连接 Connection connection = connectionFactory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 Destination destination = session.createQueue(queueName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage= (TextMessage) message; try &#123; System.out.println(\"接收消息:\"+textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 6.4 ActiveMQ客户端查看队列模式 6.5 实现生产者（主题模式）1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.snail.topic;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * 生产者（主题模式） * Create by zhangviv * 2017-08-25 14:06 **/public class TopicProducer &#123; private static final String url = \"tcp://localhost:61616\"; private static final String topicName = \"topic-test\"; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(url); //2.创建连接 Connection connection = connectionFactory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 Destination destination = session.createTopic(topicName); //6.创建一个生产者 MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; 100; i++) &#123; //7.创建消息 TextMessage textMessage = session.createTextMessage(\"test\" + i); producer.send(textMessage); System.out.println(\"发送消息：\" + textMessage.getText()); &#125; //8.关闭连接 connection.close(); &#125;&#125; 6.6 实现消费者模式（主题模式）123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.snail.topic;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * 消费者（主题模式） * Create by zhangviv * 2017-08-25 14:12 **/public class TopicConsumer &#123; private static final String url=\"tcp://localhost:61616\"; private static final String topicName=\"topic-test\"; public static void main(String[] args) throws JMSException &#123; //1.创建ConnectionFactory ConnectionFactory connectionFactory=new ActiveMQConnectionFactory(url); //2.创建连接 Connection connection = connectionFactory.createConnection(); //3.启动连接 connection.start(); //4.创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.创建一个目标 Destination destination = session.createTopic(topicName); //6.创建一个消费者 MessageConsumer consumer=session.createConsumer(destination); //7.创建一个监听器 consumer.setMessageListener(new MessageListener() &#123; public void onMessage(Message message) &#123; TextMessage textMessage= (TextMessage) message; try &#123; System.out.println(\"接收消息:\"+textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 6.7 ActiveMQ客户端查看主题模式","categories":[{"name":"MQ","slug":"MQ","permalink":"http://geekvic.top/categories/MQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://geekvic.top/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://geekvic.top/tags/JMS/"}]},{"title":"Spring Data JPA在Spring Boot中的应用","slug":"Spring Data JPA在Spring Boot中的应用","date":"2017-07-27T06:58:00.000Z","updated":"2020-05-22T06:12:48.246Z","comments":true,"path":"post/f3cd1273.html","link":"","permalink":"http://geekvic.top/post/f3cd1273.html","excerpt":"1.JPAJPA(Java Persistence API)是Sun官方提出的Java持久化规范。它为Java开发人员提供了一种对象/关联映射工具来管理Java应用中的关系数据。他的出现主要是为了简化现有的持久化开发工作和整合ORM技术，结束现在Hibernate，TopLink，JDO等ORM框架各自为营的局面。值得注意的是，JPA是在充分吸收了现有Hibernate，TopLink，JDO等ORM框架的基础上发展而来的，具有易于使用，伸缩性强等优点。JPA是一套规范，不是一套产品，那么像Hibernate,TopLink,JDO他们是一套产品，如果说这些产品实现了这个JPA规范，那么我们就可以叫他们为JPA的实现产品。 2.项目搭建本文采用IDEA搭建Spring Boot的JPA应用，Demo结构图如下： 3.具体实现3.1 配置文件","text":"1.JPAJPA(Java Persistence API)是Sun官方提出的Java持久化规范。它为Java开发人员提供了一种对象/关联映射工具来管理Java应用中的关系数据。他的出现主要是为了简化现有的持久化开发工作和整合ORM技术，结束现在Hibernate，TopLink，JDO等ORM框架各自为营的局面。值得注意的是，JPA是在充分吸收了现有Hibernate，TopLink，JDO等ORM框架的基础上发展而来的，具有易于使用，伸缩性强等优点。JPA是一套规范，不是一套产品，那么像Hibernate,TopLink,JDO他们是一套产品，如果说这些产品实现了这个JPA规范，那么我们就可以叫他们为JPA的实现产品。 2.项目搭建本文采用IDEA搭建Spring Boot的JPA应用，Demo结构图如下： 3.具体实现3.1 配置文件 pom.xml里加入spring-boot-starter-data-jpa以及mysql-connector-java的依赖，如下所示。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt;&lt;/dependency&gt; application.yml里加入hibernate、jpa的配置，以及返回json对日期字段的特殊处理配置，注意time-zone的设置，须与mysql的url配置一致，否则会引起时间相差8小时的问题。jpa里的show-sql作用，如果设置为true，执行程序后可以看在控制台里看到sql语句，如下所示。 123456789101112131415spring: profiles: active: product datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/saascrm?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=UTC username: root password: snail123 jpa: hibernate: ddl-auto: update show-sql: true jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: UTC 3.2 分层为了区别各个模块，为项目建立几个包：controller、Entity、respository、service，这是典型的MVC架构，各个层次的代表意义在此不再赘述。 3.3 Respository层spring data jpa让我们解脱了DAO层的操作，基本上所有CRUD都可以依赖于它来实现，需要实现JpaRepository接口 12public interface UserRepository extends JpaRepository&lt;UserInfo,Long&gt; &#123;&#125; 3.4 Entity层定义了用户信息表实体UserInfo，通过Hibernate与数据库形成映射关系，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Entity@Componentpublic class UserInfo &#123; public UserInfo() &#123; &#125; @Id @GeneratedValue public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getJobNumber() &#123; return jobNumber; &#125; public void setJobNumber(String jobNumber) &#123; this.jobNumber = jobNumber; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; private Long id; //ID private String name; //姓名 private String jobNumber; //工号 private Date createTime; //创建时间&#125; 3.5 service层定义了服务层接口以及服务层接口实现类，如下： UserService.java 123456789public interface UserService &#123; List&lt;UserInfo&gt; getUserList(); UserInfo getUserByName(String name); UserInfo addUserInfo(UserInfo userInfo); UserInfo updateUserInfoById(UserInfo userInfo); void deleteUserInfoById(Long Id); List&lt;UserInfo&gt;getCurrentUserList(); Page&lt;UserInfo&gt; getPageUserList();&#125; UserServiceImpl.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Servicepublic class UserServiceImpl implements UserService&#123; @Autowired private UserRepository userRepository; /** * 获取所有用户列表 * @return */ public List&lt;UserInfo&gt; getUserList()&#123; List&lt;UserInfo&gt; userList=new ArrayList&lt;UserInfo&gt;(); userList=userRepository.findAll(); return userList; &#125; /** * 通过姓名获取用户信息 * @param name 用户姓名 * @return */ public UserInfo getUserByName(String name) &#123; return userRepository.findByName(name); &#125; /** * 新增用户信息 * @param userInfo 用户信息 * @return */ public UserInfo addUserInfo(UserInfo userInfo) &#123; return userRepository.save(userInfo); &#125; /** * 更新用户信息 * @param userInfo 用户信息 * @return */ public UserInfo updateUserInfoById(UserInfo userInfo) &#123; return userRepository.save(userInfo); &#125; /** * 删除用户信息 * @param id 主键Id */ public void deleteUserInfoById(Long id) &#123; userRepository.delete(id); &#125; /** * 获取最新的用户 * @return */ public List&lt;UserInfo&gt; getCurrentUserList() &#123; Sort sort=new Sort(Sort.Direction.DESC,\"createTime\"); return userRepository.findAll(sort); &#125; /** * 获取分页的用户 * @return */ public Page&lt;UserInfo&gt; getPageUserList() &#123; Sort sort=new Sort(Sort.Direction.DESC,\"createTime\"); Pageable pageable=new PageRequest(0,5,sort); return userRepository.findAll(pageable); &#125;&#125; 3.6 Controller层其中，日期格式需要做转换，在需要日期转换的Controller中使用SpringMVC的注解@initbinder和Spring自带的WebDateBinder类来操作。WebDataBinder是用来绑定请求参数到指定的属性编辑器.由于前台传到controller里的值是String类型的，当往Model里Set这个值的时候，如果set的这个属性是个对象，Spring就会去找到对应的editor进行转换，然后再SET进去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@RestController@RequestMapping(value = \"/test\")public class TestController &#123; @Autowired private UserInfo userInfo; @Resource private UserService userService; /** * 获取所有用户 * @return */ @GetMapping(value = \"/getUserList\") public List&lt;UserInfo&gt; getUserList() &#123; return userService.getUserList(); &#125; @GetMapping(value = \"/getUserInfo\") public UserInfo getUserInfoByName(@RequestParam(\"name\") String name) &#123; return userService.getUserByName(name); &#125; @GetMapping(value = \"/getCurrentUserList\") public List&lt;UserInfo&gt; getCurrentUserList()&#123; return userService.getCurrentUserList(); &#125; @GetMapping(value=\"/getPageUserList\") public Page&lt;UserInfo&gt; getPageUserList()&#123; return userService.getPageUserList(); &#125; @PutMapping(value = \"/addUserInfo\") public UserInfo addUserInfo(UserInfo userInfo) &#123; return userService.addUserInfo(userInfo); &#125; @PostMapping(value =\"/updateUserInfo\") public UserInfo updateUserInfo(UserInfo userInfo)&#123; return userService.updateUserInfoById(userInfo); &#125; @PostMapping(value=\"/deleteUserInfo\") public void deleteUserInfo(@RequestParam(\"id\") Long id)&#123; userService.deleteUserInfoById(id); &#125; @InitBinder protected void init(HttpServletRequest request, ServletRequestDataBinder binder) &#123; SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); dateFormat.setTimeZone(TimeZone.getTimeZone(\"UTC\"));/*TimeZone时区，解决差8小时的问题*/ binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, false)); &#125; 4.测试 Http定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。URL全称是资源描述符，我们可以这样认为：一个URL地址，它用于描述一个网络上的资源，而HTTP中的GET，POST，PUT，DELETE就对应着对这个资源的查，改，增，删4个操作。 本文借助PostMan工具进行测试，如下图所示。（注意事项，如果选择PUT请求，那么只能选x-www-form-urlencoded）","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/tags/Spring-Boot/"},{"name":"JPA","slug":"JPA","permalink":"http://geekvic.top/tags/JPA/"}]},{"title":"如何将Spring Boot项目打包部署到外部Tomcat","slug":"如何将Spring Boot项目打包部署到外部Tomcat","date":"2017-07-25T16:45:00.000Z","updated":"2020-05-22T06:12:48.250Z","comments":true,"path":"post/f2b1a42.html","link":"","permalink":"http://geekvic.top/post/f2b1a42.html","excerpt":"一、项目打包项目开发结束后，需要打包部署到外部服务器的Tomcat上，主要有几种方式。 1.1 生成jar包 cd 项目跟目录（和pom.xml同级） 1mvn clean package 排除测试代码后进行打包 1mvn clean package -Dmaven.test.skip=true","text":"一、项目打包项目开发结束后，需要打包部署到外部服务器的Tomcat上，主要有几种方式。 1.1 生成jar包 cd 项目跟目录（和pom.xml同级） 1mvn clean package 排除测试代码后进行打包 1mvn clean package -Dmaven.test.skip=true 打包完成后jar包会生成到target目录下，命名一般是 项目名+版本号.jar 启动jar包命令 1java -jar target/spring-boot-scheduler-1.0.0.jar 这种方式，只要控制台关闭，服务就不能访问了。下面我们使用在后台运行的方式来启动: 1nohup java -jar target/spring-boot-scheduler-1.0.0.jar &amp; 也可以在启动的时候选择读取不同的配置文件 1java -jar app.jar --spring.profiles.active=product 也可以通过IDEA的Maven工具生成，点击Lifecycle-install，生成jar 1.2 生成war包- 修改打包类型为war1&lt;packaging&gt;war&lt;/packaging&gt; - 添加spring-boot-starter-tomcat依赖，scope设置为provided12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; - 注册启动类创建ServletInitializer.java，继承SpringBootServletInitializer ，覆盖configure()，把启动类Application注册进去。外部web应用服务器构建Web Application Context的时候，会把启动类添加进去。 123456public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(BootdemoApplication.class); &#125;&#125; - 同样也是两种方式执行： mvn clean package -Dmaven.test.skip=true 通过IDEA的Maven工具生成，点击Lifecycle-package，生成war 二、项目部署 无论是用哪种方式生成，最终都是为了进行部署，war可以直接拷到tomcat的webapps目录下，启动Tomcat即可。","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/tags/Spring-Boot/"}]},{"title":"Spring Boot项目搭建","slug":"Spring Boot项目搭建","date":"2017-07-25T15:22:00.000Z","updated":"2020-05-22T06:12:48.242Z","comments":true,"path":"post/b9022a16.html","link":"","permalink":"http://geekvic.top/post/b9022a16.html","excerpt":"一、Spring Boot概述Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。总所周知，Spring平台饱受非议的一点就是大量的XML配置以及复杂的依赖管理，而Spring Boot的出现就是用来简化操作的。相比传统的Spring，项目搭建更简单、方便、快速。 二、项目搭建本文采用IDEA搭建Spring Boot，Demo结构图如下： 通过IDEA生成Spring Boot项目很方便，具体步骤不再赘述，可以参考网上其他资料，如上图，主要生成： src/main/java 程序开发以及主程序入口 src/main/resources 配置文件 src/test/java 测试程序","text":"一、Spring Boot概述Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。总所周知，Spring平台饱受非议的一点就是大量的XML配置以及复杂的依赖管理，而Spring Boot的出现就是用来简化操作的。相比传统的Spring，项目搭建更简单、方便、快速。 二、项目搭建本文采用IDEA搭建Spring Boot，Demo结构图如下： 通过IDEA生成Spring Boot项目很方便，具体步骤不再赘述，可以参考网上其他资料，如上图，主要生成： src/main/java 程序开发以及主程序入口 src/main/resources 配置文件 src/test/java 测试程序 默认pom.xml生成jar包依赖项如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.snail&lt;/groupId&gt; &lt;artifactId&gt;bootdemo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;bootdemo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 三、测试用例Demo并没有配置数据库，只是简单地测试一下Http 请求，并结合现实中的场景，我们的配置文件往往在线下环境、生产环境的配置是不一样的，可以通过配置来获取对应的文件，如下所示。 3.1 实体类其中ConfigurationProperties注解的目的是用来映射配置文件的，会在配置文件yml文件里新建配置项application.yml、application-product.yml（生产环境）、application-test.yml（测试环境），通过前缀CustomerInfo可以获取配置文件里对应的映射。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 客户基本信息 * Create by snailTech * 2017-07-24 16:31 **/@Component@ConfigurationProperties(prefix = \"CustomerInfo\")public class CustomerInfo &#123; /** * 姓名 */ private String name; /** * 手机号码 */ private String mobile; /** * 年龄 */ private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getMobile() &#123; return mobile; &#125; public void setMobile(String mobile) &#123; this.mobile = mobile; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 3.2 application.yml123spring: profiles: active: product 通过这个配置active为product可以得知读取的是application-product.yml文件，其中port是Web容器（默认是Tomcat）的端口号，以及context-path是虚拟路径。 3.3 application-product.yml12345678server: port: 8080 context-path: /bootdemotestUrl: http://www.baidu.comCustomerInfo: name: snail mobile: 18818718711（生产环境） age: 30 3.4 application-test.yml12345678server: port: 8080 context-path: /bootdemotestUrl: http://www.baidu.comCustomerInfo: name: snail mobile: 18818718711（测试环境） age: 30 3.5 配置Controller层@RestController相当于@ResponseBody+@Controller，都是以json格式返回，@Value(“${testUrl}”)是用来获取配置文件里的testUrl配置项的，@RequestParam用来接收请求参数，其余的写法与SpringMvc的写法并没什么区别 123456789101112131415161718192021222324package com.snail;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;/** * Create by snailTech * 2017-07-24 16:10 **/@RestController@RequestMapping(value = \"/test\")public class TestController &#123; @Value(\"$&#123;testUrl&#125;\") private String testUrl; @Autowired private CustomerInfo customerInfo; //@RequestMapping(value=\"/hello\" ,method = RequestMethod.GET) @GetMapping(value = \"/hello\") public String hello(@RequestParam(\"id\") Integer xx)&#123; return customerInfo.getMobile()+xx; &#125;&#125; 3.6 编译编译非常简单，内置Tomcat，无需像SSM项目里还需要手动配置Tomcat，只要运行程序就可以了。 3.7 运行","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/tags/Spring-Boot/"}]},{"title":"基于GitLab与Git Extensions搭建版本控制工具","slug":"基于GitLab与Git Extensions搭建版本控制工具","date":"2017-05-07T03:47:00.000Z","updated":"2020-05-22T06:12:48.249Z","comments":true,"path":"post/a02754ce.html","link":"","permalink":"http://geekvic.top/post/a02754ce.html","excerpt":"1.背景 大家知道GitHub是现在非常流行的代码托管工具，但是如果有些项目不想开源的话，则需要付费，因此萌生了自己搭建一个Git的版本控制工具，供内网使用。GitLab则是个好的选择，但是GitLab只支持Linux版本，因此则需在Windows服务器上搭建个Linux的虚拟机，我选择了Ubuntu。此时服务器端选型成功，客户端需要安装什么呢，我选择了Git Extensions，用它是因为他直接集成了Git以及KDiff3工具，更方便的是这个工具自带Putty，可以很方便地生成SSH公钥和私钥。 2.环境 服务器端：Ubuntu(搭建在Win10上的虚拟机)、GitLab 客户端：Win10 Git Extensions(包括Git、KDiff3) 3.实现思路 安装Ubuntu，版本号：Ubuntu 16.04，具体安装步骤就不赘述，可以参考http://blog.csdn.net/u013142781/article/details/50529030，Ubuntu安装完发现了一个问题，屏幕太小，而且无法放大，可以通过安装Vmware Tool解决，具体可以参考http://jingyan.baidu.com/article/fc07f98977b60f12ffe5199b.html，这里需要用到Ubuntu的终端工具（类似Windows的cmd），需要采用命令行的方式去执行，刚开始有些不太习惯。（注：打开终端的快捷键:ctrl+alt+T，切换管理员的命令：sudo su） Ubuntu虚拟机与Win10宿主机的网络连接方式，有两种方式，一个是桥接模式，另一个是NAT模式。桥接模式是直接连接物理网络的，也就是桥接模式下Ubuntu虚拟机跟Win10是在同一个网段的局域网里的。好比我的Win10 IP:192.168.0.104，桥接模式下的Ubuntu的Ip是192.168.0.103;而NAT模式则是共享主机的Ip,自动生成一个IP地址，此地址跟宿主机不在一个网段里，比如我这边IP地址是：192.168.182.129。当前的业务需求是在局域网里能访问，选择了桥接模式。Ubuntu如下图所示。 安装GitLab，安装过程还算顺利，建议安装Gitlab安装包，我安装的是gitlab-ce_9.1.1-ce.0_amd64，具体步骤不再赘述，详细可参考http://blog.csdn.net/u011241606/article/details/51471367。建议把external_url设成当前IP地址。 客户端访问GitLab URL地址，如下图所示。默认账号是root","text":"1.背景 大家知道GitHub是现在非常流行的代码托管工具，但是如果有些项目不想开源的话，则需要付费，因此萌生了自己搭建一个Git的版本控制工具，供内网使用。GitLab则是个好的选择，但是GitLab只支持Linux版本，因此则需在Windows服务器上搭建个Linux的虚拟机，我选择了Ubuntu。此时服务器端选型成功，客户端需要安装什么呢，我选择了Git Extensions，用它是因为他直接集成了Git以及KDiff3工具，更方便的是这个工具自带Putty，可以很方便地生成SSH公钥和私钥。 2.环境 服务器端：Ubuntu(搭建在Win10上的虚拟机)、GitLab 客户端：Win10 Git Extensions(包括Git、KDiff3) 3.实现思路 安装Ubuntu，版本号：Ubuntu 16.04，具体安装步骤就不赘述，可以参考http://blog.csdn.net/u013142781/article/details/50529030，Ubuntu安装完发现了一个问题，屏幕太小，而且无法放大，可以通过安装Vmware Tool解决，具体可以参考http://jingyan.baidu.com/article/fc07f98977b60f12ffe5199b.html，这里需要用到Ubuntu的终端工具（类似Windows的cmd），需要采用命令行的方式去执行，刚开始有些不太习惯。（注：打开终端的快捷键:ctrl+alt+T，切换管理员的命令：sudo su） Ubuntu虚拟机与Win10宿主机的网络连接方式，有两种方式，一个是桥接模式，另一个是NAT模式。桥接模式是直接连接物理网络的，也就是桥接模式下Ubuntu虚拟机跟Win10是在同一个网段的局域网里的。好比我的Win10 IP:192.168.0.104，桥接模式下的Ubuntu的Ip是192.168.0.103;而NAT模式则是共享主机的Ip,自动生成一个IP地址，此地址跟宿主机不在一个网段里，比如我这边IP地址是：192.168.182.129。当前的业务需求是在局域网里能访问，选择了桥接模式。Ubuntu如下图所示。 安装GitLab，安装过程还算顺利，建议安装Gitlab安装包，我安装的是gitlab-ce_9.1.1-ce.0_amd64，具体步骤不再赘述，详细可参考http://blog.csdn.net/u011241606/article/details/51471367。建议把external_url设成当前IP地址。 客户端访问GitLab URL地址，如下图所示。默认账号是root 客户端安装Git Extensions，安装的过程会提醒你安装Git以及KDiff3，安装过程中基本不需求设置什么，记得选SSH客户端Putty，详细参考http://blog.csdn.net/mysouling/article/details/51304173。Git Extension可以生成公钥、私钥，公钥是要放到GitHub、GitLab里面的，私钥是存在本地，每次拉取代码或者克隆代码通过Pageant需要加载的。每个用户都对应一个公钥、一个私钥。GitLab在Setting的SSH keys里面设置，如下图所示。 Git Extensions安装完，在Git Extensions里新建Group、项目、用户等，具体操作不再赘述，GitLab已经部署好，这样就可以上传代码到GitLab里，然后通过Git Extensions通过SSH Git地址拉取代码，提交到本地仓库，提交到远程Git仓库（GitLab里）。如下图所示。 在使用过程中，发现当GitLab修改了IP地址，但是SSH地址（如git@192.168.0.103:zhangviv/develop.git）还是原来的地址，则需要进行修改，具体用法参考http://blog.csdn.net/lcalqf/article/details/54862046。","categories":[{"name":"Git","slug":"Git","permalink":"http://geekvic.top/categories/Git/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://geekvic.top/tags/Gitlab/"}]},{"title":"认识浏览器缓存","slug":"认识浏览器缓存","date":"2017-04-02T05:36:00.000Z","updated":"2020-05-22T06:12:48.252Z","comments":true,"path":"post/62fb758b.html","link":"","permalink":"http://geekvic.top/post/62fb758b.html","excerpt":"浏览器缓存，也就是客户端缓存,既是网页性能优化里面静态资源相关优化的一大利器，也是无数web开发人员在工作过程不可避免的一大问题。浏览器缓存分为：强缓存和协商缓存 一、原理 浏览器加载资源时，先根据这个资源的http header中的Cache-Control判断是否命中强缓存，如果命中，浏览器直接从缓存中读取资源，根本不会向服务器发送请求； 当强缓存没有命中的时候，浏览器则会发送一个请求到服务器，通过资源的http header中的 Last-Modified 和If-Modified-Since来判断资源是否命中协商缓存，如果命中，服务器将会将这个请求返回，但不会返回这个资源的数据，而是告诉客服端可以从缓存中加载这个资源； 如果资源也没有命中协商缓存的话，浏览器直接从服务器端加载资源数据 二、共同点与区别 共同点：如果命中，都从客户端缓存中加载这个资源，而不从服务器端加载； 区别： 强缓存不发请求到服务器，协商缓存发请求到服务器； 三、强缓存原理命中强缓存，chrome里的network里面 status是200，且size会显示为from disk/memory cache,Cache Control :max-age:315360000 单位秒，也就是10年","text":"浏览器缓存，也就是客户端缓存,既是网页性能优化里面静态资源相关优化的一大利器，也是无数web开发人员在工作过程不可避免的一大问题。浏览器缓存分为：强缓存和协商缓存 一、原理 浏览器加载资源时，先根据这个资源的http header中的Cache-Control判断是否命中强缓存，如果命中，浏览器直接从缓存中读取资源，根本不会向服务器发送请求； 当强缓存没有命中的时候，浏览器则会发送一个请求到服务器，通过资源的http header中的 Last-Modified 和If-Modified-Since来判断资源是否命中协商缓存，如果命中，服务器将会将这个请求返回，但不会返回这个资源的数据，而是告诉客服端可以从缓存中加载这个资源； 如果资源也没有命中协商缓存的话，浏览器直接从服务器端加载资源数据 二、共同点与区别 共同点：如果命中，都从客户端缓存中加载这个资源，而不从服务器端加载； 区别： 强缓存不发请求到服务器，协商缓存发请求到服务器； 三、强缓存原理命中强缓存，chrome里的network里面 status是200，且size会显示为from disk/memory cache,Cache Control :max-age:315360000 单位秒，也就是10年 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Cache-Control的header 浏览器接收到这个资源后，会把这个资源连同所有的resoponse Header缓存下来 浏览器再次请求这个资源时，会从缓存中寻找，找到后，根据它第一次请求时间和Cache Control设定的有效期，计算一个过期时间。再拿这个过期时间跟当前请求时间比较，如果当前请求时间在过期时间之前，就能命中缓存。否则，就不行。 四、协商缓存原理 如果协商缓存命中，请求响应返回的http状态为304并且会显示一个Not Modified的字符串。协商缓存是利用的是【Last-Modified，If-Modified-Since】 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Last-Modified的header，这个header表示这个资源在服务器上的最后修改时间；浏览器再次跟服务器请求这个资源时，在request的header上加上If-Modified-Since的header，这个header的值就是上一次请求时返回的Last-Modified的值； 服务器再次收到资源请求时，根据浏览器传过来If-Modified-Since和资源在服务器上的Last-Modified是否有变化，如果没有变化则返回304 Not Modified，但是不会返回资源内容；如果有变化，就正常返回资源内容。 五、清除客户端缓存的方法 当ctrl+f5强制刷新网页时，直接从服务器加载，跳过强缓存和协商缓存； 当f5刷新网页时，跳过强缓存，但是会检查协商缓存； 如果用的是chrome，可以f12在network那里把缓存给禁掉 Disable cache 给资源加上一个动态的参数，css/index.css?v=2017032901","categories":[{"name":"web","slug":"web","permalink":"http://geekvic.top/categories/web/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://geekvic.top/tags/%E7%BC%93%E5%AD%98/"}]}],"categories":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/categories/Redis/"},{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/categories/Hexo/"},{"name":"Devops","slug":"Devops","permalink":"http://geekvic.top/categories/Devops/"},{"name":"配置管理","slug":"配置管理","permalink":"http://geekvic.top/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"工具","slug":"工具","permalink":"http://geekvic.top/categories/%E5%B7%A5%E5%85%B7/"},{"name":"微服务","slug":"微服务","permalink":"http://geekvic.top/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Java基础","slug":"Java基础","permalink":"http://geekvic.top/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://geekvic.top/categories/zookeeper/"},{"name":"Nginx","slug":"Nginx","permalink":"http://geekvic.top/categories/Nginx/"},{"name":"Git","slug":"Git","permalink":"http://geekvic.top/categories/Git/"},{"name":"通信协议","slug":"通信协议","permalink":"http://geekvic.top/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"},{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/categories/Linux/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/categories/Spring-Boot/"},{"name":"MQ","slug":"MQ","permalink":"http://geekvic.top/categories/MQ/"},{"name":"web","slug":"web","permalink":"http://geekvic.top/categories/web/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://geekvic.top/tags/Redis/"},{"name":"高可用","slug":"高可用","permalink":"http://geekvic.top/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"cluster","slug":"cluster","permalink":"http://geekvic.top/tags/cluster/"},{"name":"主从复制","slug":"主从复制","permalink":"http://geekvic.top/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"name":"哨兵","slug":"哨兵","permalink":"http://geekvic.top/tags/%E5%93%A8%E5%85%B5/"},{"name":"持久化","slug":"持久化","permalink":"http://geekvic.top/tags/%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"Hexo","slug":"Hexo","permalink":"http://geekvic.top/tags/Hexo/"},{"name":"Next","slug":"Next","permalink":"http://geekvic.top/tags/Next/"},{"name":"Git","slug":"Git","permalink":"http://geekvic.top/tags/Git/"},{"name":"node.js","slug":"node-js","permalink":"http://geekvic.top/tags/node-js/"},{"name":"Docker","slug":"Docker","permalink":"http://geekvic.top/tags/Docker/"},{"name":"prometheus","slug":"prometheus","permalink":"http://geekvic.top/tags/prometheus/"},{"name":"grafana","slug":"grafana","permalink":"http://geekvic.top/tags/grafana/"},{"name":"alertmanager","slug":"alertmanager","permalink":"http://geekvic.top/tags/alertmanager/"},{"name":"ES","slug":"ES","permalink":"http://geekvic.top/tags/ES/"},{"name":"Logstash","slug":"Logstash","permalink":"http://geekvic.top/tags/Logstash/"},{"name":"Kibana","slug":"Kibana","permalink":"http://geekvic.top/tags/Kibana/"},{"name":"Apollo","slug":"Apollo","permalink":"http://geekvic.top/tags/Apollo/"},{"name":"FFmpeg","slug":"FFmpeg","permalink":"http://geekvic.top/tags/FFmpeg/"},{"name":"Dubbo","slug":"Dubbo","permalink":"http://geekvic.top/tags/Dubbo/"},{"name":"Mysql","slug":"Mysql","permalink":"http://geekvic.top/tags/Mysql/"},{"name":"Java","slug":"Java","permalink":"http://geekvic.top/tags/Java/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://geekvic.top/tags/zookeeper/"},{"name":"frp","slug":"frp","permalink":"http://geekvic.top/tags/frp/"},{"name":"Nginx","slug":"Nginx","permalink":"http://geekvic.top/tags/Nginx/"},{"name":"GitLab","slug":"GitLab","permalink":"http://geekvic.top/tags/GitLab/"},{"name":"Protobuf","slug":"Protobuf","permalink":"http://geekvic.top/tags/Protobuf/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://geekvic.top/tags/ubuntu/"},{"name":"redis","slug":"redis","permalink":"http://geekvic.top/tags/redis/"},{"name":"apt-get","slug":"apt-get","permalink":"http://geekvic.top/tags/apt-get/"},{"name":"Linux","slug":"Linux","permalink":"http://geekvic.top/tags/Linux/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://geekvic.top/tags/Spring-Boot/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://geekvic.top/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://geekvic.top/tags/JMS/"},{"name":"JPA","slug":"JPA","permalink":"http://geekvic.top/tags/JPA/"},{"name":"Gitlab","slug":"Gitlab","permalink":"http://geekvic.top/tags/Gitlab/"},{"name":"缓存","slug":"缓存","permalink":"http://geekvic.top/tags/%E7%BC%93%E5%AD%98/"}]}